{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc4dca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all okay\n"
     ]
    }
   ],
   "source": [
    "print(\"all okay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e05988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2acf511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGSMITH_API_KEY=os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT=os.getenv(\"LANGSMITH_PROJECT\")\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "SERPER_API_KEY=os.getenv(\"SERPER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ac5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"]=GOOGLE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]=GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGSMITH_API_KEY\"]=LANGSMITH_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"]=LANGSMITH_PROJECT\n",
    "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"]=TAVILY_API_KEY\n",
    "os.environ[\"SERPER_API_KEY\"]=SERPER_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2f27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeladnatarajan/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761334581.155132  323343 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1761334581.160999  323343 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-pro\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7efe28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm2 = ChatGroq(model=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13411ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! Thanks for asking.\\n\\nAs an AI, I don't have feelings, but I'm functioning perfectly and I'm ready to help.\\n\\nWhat can I do for you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--b9604448-feeb-42ca-95ad-fa0505da779a-0', usage_metadata={'input_tokens': 6, 'output_tokens': 41, 'total_tokens': 1155, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de24ba7",
   "metadata": {},
   "source": [
    "## Simple AI Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02faa222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoodBye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"Type your question. If you want to quit the chat write quit\")\n",
    "    if question.lower() != \"quit\":\n",
    "        print(llm.invoke(question).content)\n",
    "    else:\n",
    "        print(\"GoodBye!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da2cb479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langgraph-prerequisite'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGSMITH_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dc95911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761334797.293548  323343 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001 ['embedText', 'countTextTokens']\n",
      "models/gemini-2.5-pro-preview-03-25 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-05-20 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-06-17 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-05-06 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-06-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp-image-generation ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-preview-image-generation ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-exp-1206 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-tts ['countTokens', 'generateContent']\n",
      "models/gemini-2.5-pro-preview-tts ['countTokens', 'generateContent']\n",
      "models/learnlm-2.0-flash-experimental ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e4b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e2b-it ['generateContent', 'countTokens']\n",
      "models/gemini-flash-latest ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-flash-lite-latest ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-pro-latest ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-image-preview ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-image ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-preview-09-2025 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-09-2025 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-robotics-er-1.5-preview ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-computer-use-preview-10-2025 ['generateContent', 'countTokens']\n",
      "models/embedding-001 ['embedContent']\n",
      "models/text-embedding-004 ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-exp ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-001 ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
      "models/aqa ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 ['predict']\n",
      "models/imagen-4.0-generate-preview-06-06 ['predict']\n",
      "models/imagen-4.0-ultra-generate-preview-06-06 ['predict']\n",
      "models/imagen-4.0-generate-001 ['predict']\n",
      "models/imagen-4.0-ultra-generate-001 ['predict']\n",
      "models/imagen-4.0-fast-generate-001 ['predict']\n",
      "models/veo-2.0-generate-001 ['predictLongRunning']\n",
      "models/veo-3.0-generate-preview ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-preview ['predictLongRunning']\n",
      "models/veo-3.0-generate-001 ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-001 ['predictLongRunning']\n",
      "models/veo-3.1-generate-preview ['predictLongRunning']\n",
      "models/veo-3.1-fast-generate-preview ['predictLongRunning']\n",
      "models/gemini-2.0-flash-live-001 ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-live-2.5-flash-preview ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-live-preview ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-native-audio-latest ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025 ['countTokens', 'bidiGenerateContent']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "models = genai.list_models()\n",
    "for m in models:\n",
    "    print(m.name, m.supported_generation_methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23597de2",
   "metadata": {},
   "source": [
    "## RAG based LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9f870cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ecacc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0994ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbcd0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"firstchat\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e133145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory = RunnableWithMessageHistory(llm, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb90b6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Neela Natarajan! It's nice to meet you.\\n\\nHow can I help you today?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"Hi! I'm neela natarajan\"), config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716a599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm neela natarajan\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Neela Natarajan! It's nice to meet you.\\n\\nHow can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--9ae080b4-2c53-4bce-b9ce-8cd3e77134d2-0', usage_metadata={'input_tokens': 11, 'output_tokens': 23, 'total_tokens': 749, 'input_token_details': {'cache_read': 0}})])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c5362d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on what you told me, your name is Neela Natarajan.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--fea8484a-fc8b-432f-a703-1e94f8780184-0', usage_metadata={'input_tokens': 43, 'output_tokens': 16, 'total_tokens': 451, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke(\"tell me what is my name?\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e689fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761334813.390941  323343 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "### Reading the text files from source directory\n",
    "\n",
    "loader = DirectoryLoader('../data', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "### BGE Embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "\n",
    "db = Chroma.from_documents(new_docs, embedding=embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbda1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fcbee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "| prompt\n",
    "| llm\n",
    "| StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3329e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, Llama 3 is a model. Here are 3 important points:\n",
      "\n",
      "1.  It was released in April 2024.\n",
      "2.  There is an 8B parameter version of Llama 3.\n",
      "3.  Meta is associated with the release of Llama 3.\n"
     ]
    }
   ],
   "source": [
    "question = \"what is llama3? can you highlight 3 important points?\"\n",
    "print(retrieval_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b3c498",
   "metadata": {},
   "source": [
    "## Tools and Agents using LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63279fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "977cdf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adc759e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f08d43a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecd2e79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "284c0938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'query to look up on wikipedia',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "070d02b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.return_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86f0eff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Vector database\n",
      "Summary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\n",
      "Vectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the\n"
     ]
    }
   ],
   "source": [
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acc5c4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Vector database\\nSummary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\\nVectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd3eef",
   "metadata": {},
   "source": [
    "### Youtube search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b46995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d94e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2=YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26594e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube_search'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool2.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa883868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=HFFcMRtqH5A&pp=ygUVcmFtYXN3YW15IHN1YnJhbWFuaWFu', 'https://www.youtube.com/watch?v=KmF1DDjhC8g&pp=ygUVcmFtYXN3YW15IHN1YnJhbWFuaWFu0gcJCQYKAYcqIYzv']\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool2.run(\"ramaswamy subramanian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f4a51",
   "metadata": {},
   "source": [
    "### Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57118ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a0bcdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/4n__nk894pn8cc6by3xc1xr00000gn/T/ipykernel_30292/140006202.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tool3=TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "tool3=TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6ca47b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'SC hearing on Karur stampede updates: SC transfers probe to CBI ...',\n",
       "  'url': 'https://www.thehindu.com/news/national/tamil-nadu/supreme-court-hearing-on-karur-stampede-tvk-independent-probe-live-updates/article70157240.ece',\n",
       "  'content': 'Karur stampede hearing updates: Follow The Hindu’s live updates as the Supreme Court will hear petitions related to the Karur stampede on October 10, 2025\\n\\nAs many as 41 persons including nine children died during a stampede that happened in Karur, Tamil Nadu on September 27, 2025 (Saturday) at Tamilaga Vettri Kazhagam (TVK) president and actor Vijay’s rally. This is a timeline of events.\\n\\n### Karur stampede: A visual timeline [...] Justice Aruna Jagatheesan of the one-woman inquiry commission set up to investigate the stampede during TVK campaign in Karur started her inquiry at the venue.\\n| Photo Credit:\\nVengadesh R.\\n\\nThis liveblog is now closed.\\n\\nThe Supreme Court on Monday (October 13, 2025) directed the Central Bureau of Investigation (CBI) to probe the Karur stampede, which occurred on September 27 during a rally organised by actor Vijay’s political outfit, Tamilaga Vettri Kazhagam (TVK), and claimed 41 lives. [...] DMK exposes attempt to mislead Supreme Court in Karur stampede case, calling it a dangerous political manipulation.\\n\\nThe Supreme Court on Friday (October 10, 2025) asked the Tamil Nadu government if the post-mortems of those who died in the Karur stampede were conducted in just three to four hours after the tragedy.',\n",
       "  'score': 0.84918517},\n",
       " {'title': 'Karur stampede | Where there was no way out - The Hindu',\n",
       "  'url': 'https://www.thehindu.com/news/national/tamil-nadu/karur-stampede-where-there-was-no-way-out/article70121911.ece',\n",
       "  'content': \"## As many as 41 persons including nine children died during a stampede that happened in Karur, Tamil Nadu on September 27, 2025 (Saturday) at Tamilaga Vettri Kazhagam (TVK) president and actor Vijay's rally. This is a timeline of events.\\n\\n7:20 p.m. Mr. Vijay begins his speech at the designated spot for his public address at Velusamypuram in Karur.\\n\\nDuring rally\\n\\nBy this time, incidents of fainting and complaints of water shortage are reported. [...] September 28, 2025 (Sunday)\\n\\nAfter the rally, the road is covered with torn slippers and party\\nflags, while roadside structures are found damaged.\\n\\nWrecked tin roof\\n\\nWrecked tin roof\\n\\nSlippers, torn party flags\\n\\nSlippers, torn party flags\\n\\n3 a.m. Chief Minister Mr. Stalin rushes from Chennai, taking a flight to Tiruchi and then travelling to Karur on road. He visits the injured at Karur Government Medical College Hospital and briefs journalists on the situation. [...] ## On September 27, thousands of people gathered in Karur, Tamil Nadu, to attend a rally by actor-turned-politician Vijay. As the chief of the Tamilaga Vettri Kazhagam party arrived hours late, the crowd swelled and surged towards his vehicle, triggering a stampede that killed 41 people and injured over 100. C.Jaisankarand Nacchinarkkiniyan M.report on the tragedy, caused by many factors, including poor planning and alleged security lapses\\n\\nUpdated  - October 08, 2025 07:50 pm IST\",\n",
       "  'score': 0.8440111},\n",
       " {'title': 'Karur stampede: A visual timeline - The Hindu',\n",
       "  'url': 'https://www.thehindu.com/news/national/tamil-nadu/karur-stampede-september-27-2025-tvk-vijay-visual-timeline/article70126058.ece',\n",
       "  'content': \"Shoes and slippers piled up at Velusamypuram in Karur, the site of a stampede during a TVK campaign rally, on September 28, 2025\\n| Photo Credit: R. Vengadesh\\n\\n## As many as 41 persons including nine children died during a stampede that happened in Karur, Tamil Nadu on September 27, 2025 (Saturday) at Tamilaga Vettri Kazhagam (TVK) president and actor Vijay's rally. This is a timeline of events. [...] September 28, 2025 (Sunday)\\n\\nAfter the rally, the road is covered with torn slippers and party\\nflags, while roadside structures are found damaged.\\n\\nWrecked tin roof\\n\\nWrecked tin roof\\n\\nSlippers, torn party flags\\n\\nSlippers, torn party flags\\n\\n3 a.m. Chief Minister Mr. Stalin rushes from Chennai, taking a flight to Tiruchi and then travelling to Karur on road. He visits the injured at Karur Government Medical College Hospital and briefs journalists on the situation. [...] ## This timeline breaks down the sequence of events that unfolded on the day of a stampede that claimed 41 lives so far at Velusamypuram in Karur district of Tamil Nadu during the political rally of actor and Tamilaga Vettri Kazhagam (TVK) president Vijay on September 27, 2025\\n\\nUpdated  - October 07, 2025 07:10 pm IST\\n\\nGoogle Preferred Source\\nShoes and slippers piled up at Velusamypuram in Karur, the site of a stampede during a TVK campaign rally, on September 28, 2025\",\n",
       "  'score': 0.8335554},\n",
       " {'title': '2025 Karur crowd crush - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/2025_Karur_crowd_crush',\n",
       "  'content': 'On 27 September 2025, at least 41 people were killed and around 100 others were injured in a crowd crush during a political rally in Karur district, Tamil Nadu, India. The rally was hosted by Vijay \"Vijay (actor)\"), the founder and president of the Tamilaga Vettri Kazhagam (TVK). The crowd crush happened in Velusamypuram on the Karur–Erode highway, when large sections of the crowd surged towards Vijay in an attempt to catch a glimpse of his convoy after his arrival was delayed by nearly seven [...] ## Incident\\n\\nAs per eyewitnesses, the fatal crowd crush happened around 7:45 p.m., when large sections of the crowd surged toward the stage barricades. Three separate crowd crushes were reported during the rally; the first caused by attendees trying to see Vijay (who did not turn on his customary spotlight), the second by attendees\\' attempts to hear him after his microphone failed, and the final crush by attendees chasing his departing bus. [...] The TVK party members and attendees formed vehicular convoys in front of and behind Vijay\\'s campaign vehicle, blocking the roads. Once the campaign vehicle arrived at the rally venue, the crowd was forced to make way, leading to a crush. The crush was triggered near a shed housing a generator and a television broadcast van, where people were pushed and subsequently trampled underfoot. A lack of buffer zones around the stage caused people to press closer, increasing overcrowding and pressure',\n",
       "  'score': 0.7711725},\n",
       " {'title': 'As CBI probes Karur stampede, is Vijay at an electoral crossroads?',\n",
       "  'url': 'https://www.indiatoday.in/india-today-insight/story/as-cbi-probes-karur-stampede-is-vijay-at-an-electoral-crossroads-2806235-2025-10-21',\n",
       "  'content': 'The TVK, once seen as a new force that could reshape the state’s political arithmetic, is facing its first major public crisis. Vijay’s rally in Karur on September 27 ended in tragedy with a stampede that left 41 people dead, many of them women and children. [...] The Karur incident has shaken public confidence and exposed organisational gaps in the TVK. On October 13, the Supreme Court ordered a CBI (Central Bureau of Investigation) probe and named a three-member supervisory panel, headed by retired Supreme Court judge Ajay Rastogi, to monitor the investigation. The CBI team has since begun preliminary work on the case. [...] For the DMK, the unfolding scenario has only strengthened its position. The combination of ideological clarity, administrative stability, alliance strength and a fragmented Opposition continues to work in its favour. The AIADMK remains weakened and uncertain; the BJP’s presence, though louder than before, remains limited in electoral scope. The Karur stampede has, in effect, shifted the narrative from Vijay’s star power to his political preparedness—or arguably the lack of it. The tragedy',\n",
       "  'score': 0.74385756}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool3.invoke({\"query\": \"what happened in the latest karur stampede?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbbcbe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeladnatarajan/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65c071fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiInputs(BaseModel):\n",
    "    query: str = Field(description=\"query to look up in Wikipedia, should be 3 or less words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f643cc02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for WikipediaQueryRun\nargs_schema\n  Input should be a subclass of BaseModel [type=is_subclass_of, input_value=<class '__main__.WikiInputs'>, input_type=ModelMetaclass]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_subclass_of",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tool = \u001b[43mWikipediaQueryRun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwiki-tool\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlook up things in wikipedia\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWikiInputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_wrapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_direct\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/tools/base.py:525\u001b[39m, in \u001b[36mBaseTool.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    520\u001b[39m     msg = (\n\u001b[32m    521\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33margs_schema must be a subclass of pydantic BaseModel or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33ma JSON schema dict. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[33m'\u001b[39m\u001b[33margs_schema\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    523\u001b[39m     )\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/load/serializable.py:115\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for WikipediaQueryRun\nargs_schema\n  Input should be a subclass of BaseModel [type=is_subclass_of, input_value=<class '__main__.WikiInputs'>, input_type=ModelMetaclass]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_subclass_of"
     ]
    }
   ],
   "source": [
    "tool = WikipediaQueryRun(\n",
    "    name=\"wiki-tool\",\n",
    "    description=\"look up things in wikipedia\",\n",
    "    args_schema=WikiInputs,\n",
    "    api_wrapper=api_wrapper,\n",
    "    return_direct=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575afa18",
   "metadata": {},
   "source": [
    "## Predefined Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5a666c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Vector database\n",
      "Summary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\n",
      "Vectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector's position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.\n",
      "These feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other.\n",
      "Vector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.\n",
      "Vector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database. Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents. These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.\n",
      "\n",
      "\n",
      "\n",
      "Page: Model Context Protocol\n",
      "Summary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "print(tool.run({\"query\": \"Langchain\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476fbcce",
   "metadata": {},
   "source": [
    "## Create a custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01ecd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "@tool\n",
    "def get_word_length(word:str) -> int:\n",
    "    \"\"\" Returns the length of the given word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31a2232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/4n__nk894pn8cc6by3xc1xr00000gn/T/ipykernel_30292/1301386445.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(get_word_length(\"MeenakshiRamaswamy\"))\n"
     ]
    }
   ],
   "source": [
    "print(get_word_length(\"MeenakshiRamaswamy\"))\n",
    "print(get_word_length(\"NeeladeviNatarajan\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "323b79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\" Returns the product of two integers.\"\"\" \n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "461c39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def summation(a: int, b: int) -> int:\n",
    "    \"\"\" Returns the sum of two integers.\"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1af6164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Returns the product of two integers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "305283a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"a\": 5, \"b\": 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9546540c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.invoke({\"a\": 9, \"b\": 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9671cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdbd3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf9c48ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/4n__nk894pn8cc6by3xc1xr00000gn/T/ipykernel_30292/2117554390.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent=initialize_agent(tool, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "agent=initialize_agent(tool, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cf957a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/4n__nk894pn8cc6by3xc1xr00000gn/T/ipykernel_30292/3516414516.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(\"How to learn Langchain and Langgraph?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `Thought\nThe user wants to know how to learn Langchain and Langgraph. I should provide a structured learning path, starting with the foundational library (Langchain) and then moving to the more advanced one (Langgraph). I'll need to explain what each one is, why one should be learned before the other, and provide key concepts and resources for both.\n\nFirst, I'll use Wikipedia to get a high-level overview of Langchain to ground the explanation. Langgraph is newer and might not have a Wikipedia page, but it's a component of the Langchain ecosystem, so understanding Langchain is the priority.\n\nAfter getting the general context, I will outline a step-by-step learning plan with resources.\n\n1.  **Define Langchain and Langgraph**: Use Wikipedia for Langchain to get a formal definition. Explain the relationship between the two.\n2.  **Propose a Learning Path**: Recommend starting with Langchain basics before moving to Langgraph.\n3.  **List Key Concepts for Langchain**: Break down the essential components of Langchain to focus on.\n4.  **List Key Concepts for Langgraph**: Explain what Langgraph adds and its core ideas.\n5.  **Provide Resources**: Point to official documentation, tutorials, and communities.Action\nwikipedia\nAction Input: LangChain`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/agent.py:1352\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1351\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/agent.py:801\u001b[39m, in \u001b[36mAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, **kwargs)\u001b[39m\n\u001b[32m    800\u001b[39m full_output = \u001b[38;5;28mself\u001b[39m.llm_chain.predict(callbacks=callbacks, **full_inputs)\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput_parser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/mrkl/output_parser.py:80\u001b[39m, in \u001b[36mMRKLOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     79\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[32m     81\u001b[39m         msg,\n\u001b[32m     82\u001b[39m         observation=MISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[32m     83\u001b[39m         llm_output=text,\n\u001b[32m     84\u001b[39m         send_to_llm=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     85\u001b[39m     )\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re.search(\n\u001b[32m     87\u001b[39m     \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]*Action\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*Input\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*:[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]*(.*)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     88\u001b[39m     text,\n\u001b[32m     89\u001b[39m     re.DOTALL,\n\u001b[32m     90\u001b[39m ):\n",
      "\u001b[31mOutputParserException\u001b[39m: Could not parse LLM output: `Thought\nThe user wants to know how to learn Langchain and Langgraph. I should provide a structured learning path, starting with the foundational library (Langchain) and then moving to the more advanced one (Langgraph). I'll need to explain what each one is, why one should be learned before the other, and provide key concepts and resources for both.\n\nFirst, I'll use Wikipedia to get a high-level overview of Langchain to ground the explanation. Langgraph is newer and might not have a Wikipedia page, but it's a component of the Langchain ecosystem, so understanding Langchain is the priority.\n\nAfter getting the general context, I will outline a step-by-step learning plan with resources.\n\n1.  **Define Langchain and Langgraph**: Use Wikipedia for Langchain to get a formal definition. Explain the relationship between the two.\n2.  **Propose a Learning Path**: Recommend starting with Langchain basics before moving to Langgraph.\n3.  **List Key Concepts for Langchain**: Break down the essential components of Langchain to focus on.\n4.  **List Key Concepts for Langgraph**: Explain what Langgraph adds and its core ideas.\n5.  **Provide Resources**: Point to official documentation, tutorials, and communities.Action\nwikipedia\nAction Input: LangChain`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHow to learn Langchain and Langgraph?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:193\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    192\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/chains/base.py:627\u001b[39m, in \u001b[36mChain.run\u001b[39m\u001b[34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33m`run` supports only one positional argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    626\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[32m    628\u001b[39m         _output_key\n\u001b[32m    629\u001b[39m     ]\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[32m    633\u001b[39m         _output_key\n\u001b[32m    634\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:193\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    192\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/chains/base.py:410\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    379\u001b[39m \n\u001b[32m    380\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    401\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    403\u001b[39m config = {\n\u001b[32m    404\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    405\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    406\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    407\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    408\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/chains/base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1334\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/agent.py:1369\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[32m   1363\u001b[39m     msg = (\n\u001b[32m   1364\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn output parsing error occurred. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1365\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1366\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1367\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1368\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1370\u001b[39m text = \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[31mValueError\u001b[39m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `Thought\nThe user wants to know how to learn Langchain and Langgraph. I should provide a structured learning path, starting with the foundational library (Langchain) and then moving to the more advanced one (Langgraph). I'll need to explain what each one is, why one should be learned before the other, and provide key concepts and resources for both.\n\nFirst, I'll use Wikipedia to get a high-level overview of Langchain to ground the explanation. Langgraph is newer and might not have a Wikipedia page, but it's a component of the Langchain ecosystem, so understanding Langchain is the priority.\n\nAfter getting the general context, I will outline a step-by-step learning plan with resources.\n\n1.  **Define Langchain and Langgraph**: Use Wikipedia for Langchain to get a formal definition. Explain the relationship between the two.\n2.  **Propose a Learning Path**: Recommend starting with Langchain basics before moving to Langgraph.\n3.  **List Key Concepts for Langchain**: Break down the essential components of Langchain to focus on.\n4.  **List Key Concepts for Langgraph**: Explain what Langgraph adds and its core ideas.\n5.  **Provide Resources**: Point to official documentation, tutorials, and communities.Action\nwikipedia\nAction Input: LangChain`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "agent.run(\"How to learn Langchain and Langgraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "976c7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "340c7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dde9ef15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'High humidity with rain expected today; AQI improves | Chennai News',\n",
       "  'url': 'https://timesofindia.indiatimes.com/city/chennai/chennai-weather-update-patchy-rain-and-moderate-temperatures-expected-today/articleshow/124774193.cms',\n",
       "  'content': \"Chennai residents can expect scattered showers on October 24, 2025, with temperatures ranging between 23.4°C and 27°C and high humidity of 85%. The city's air quality index measured moderate at AQI-IN 62 yesterday, showing improvement from earlier in the week. The day will see winds at 22 km/h with an 89% chance of rain, particularly intensifying in the late afternoon.The morning will start with patchy rain and moderate humidity, creating muggy conditions. Light rain is expected to pick up by [...] Rao Narender Singh\\n\\nKasganj Parking Dispute\\n\\nDK Shivakumar\\n\\nMumbai Fire\\n\\nChennai Rains\\n\\n# Chennai weather: High humidity with rain expected today; AQI improves\\n\\nTIMESOFINDIA.COM / Updated: Oct 24, 2025, 17:47 IST\\n\\nShare\\n\\nAA\\n\\nText Size\\n\\n Small\\n Medium\\n Large [...] The weather outlook for the coming week shows varied conditions.October 25 will bring heavy rain with a high of 29.7°C, followed by patchy rain on October 26 with temperatures at 26.7°C.October 27 will experience moderate rain and strong winds at 32.4 km/h. October 28 will see a mix of sun and rain, with temperatures reaching 30.5°C.The week will conclude with sunny conditions on October 29 and 30, with temperatures rising to 31.9°C. The overall temperature range for the week will remain\",\n",
       "  'score': 0.9708237},\n",
       " {'title': 'Chennai weather in October 2025 - Weather25.com',\n",
       "  'url': 'https://www.weather25.com/asia/india/tamil-nadu/chennai?page=month&month=October',\n",
       "  'content': 'United States England Australia Canada\\n\\n°F °C\\n\\nWeather in October 2025\\n\\n1. Home\\n2. Asia\\n3. India\\n4. Tamil Nadu\\n5. Chennai\\n6. October\\n\\nLocation was added to My Locations\\n\\nLocation was removed from My Locations\\n\\n# Chennai weather in October 2025\\n\\nClick on a day for an hourly weather forecast\\n\\nOct 24\\n\\n3.8 mm\\n\\n28° / 25°Oct 25\\n\\n4.3 mm\\n\\n31° / 24°Oct 26\\n\\n14.8 mm\\n\\n28° / 26°Monday\\n\\nOct 27\\n\\n43.3 mm\\n\\n24° / 24°Tuesday\\n\\nOct 28\\n\\n0 mm\\n\\n29° / 24°Wednesday\\n\\nOct 29\\n\\n0 mm\\n\\n32° / 25°Thursday\\n\\nOct 30\\n\\n0 mm [...] 32° / 27°\\n\\nRainy Days\\n\\n11\\n\\nSnowy Days\\n\\n0\\n\\nDry Days\\n\\n20\\n\\nRainfall\\n\\n292\\n\\nmm\\n\\nSun Hours\\n\\n11.3\\n\\nHrs\\n\\nHistoric average weather for October\\n\\nOctober [...] | 26  28° /26° | 27  24° /24° | 28  29° /24° | 29  32° /25° | 30  32° /27° | 31  31° /27° |',\n",
       "  'score': 0.94225764},\n",
       " {'title': 'Weather Chennai in October 2025: Temperature & Climate',\n",
       "  'url': 'https://en.climate-data.org/asia/india/tamil-nadu/chennai-1003222/t/october-10/',\n",
       "  'content': '|  |  |  |  |  |  |\\n ---  ---  --- |\\n|  | Temperature October | 27.3°C | 81.1°F |  | Precipitation / Rainfall October | 223mm | 8.8 inches |\\n|  | Temperature October max. | 30.6°C | 87°F |  | Water Temperature October | 29°C | 85°F |\\n|  | Temperature October min. | 24.6°C | 76.3°F | [...] 24.3 °C\\n\\n(75.7) °F\\n\\n25.3 °C\\n\\n(77.5) °F\\n\\n27.4 °C\\n\\n(81.2) °F\\n\\n29.6 °C\\n\\n(85.3) °F\\n\\n31.3 °C\\n\\n(88.4) °F\\n\\n30.8 °C\\n\\n(87.5) °F\\n\\n30 °C\\n\\n(86) °F\\n\\n29.2 °C\\n\\n(84.6) °F\\n\\n28.7 °C\\n\\n(83.7) °F\\n\\n27.3 °C\\n\\n(81.1) °F\\n\\n25.7 °C\\n\\n(78.3) °F\\n\\n24.6 °C\\n\\n(76.3) °F\\n\\n20.8 °C\\n\\n(69.5) °F\\n\\n21 °C\\n\\n(69.9) °F\\n\\n23.1 °C\\n\\n(73.5) °F\\n\\n26.2 °C\\n\\n(79.1) °F\\n\\n28 °C\\n\\n(82.4) °F\\n\\n27.7 °C\\n\\n(81.9) °F\\n\\n27 °C\\n\\n(80.7) °F\\n\\n26.4 °C\\n\\n(79.5) °F\\n\\n26 °C\\n\\n(78.7) °F\\n\\n24.6 °C\\n\\n(76.3) °F\\n\\n23.3 °C\\n\\n(73.9) °F\\n\\n22 °C\\n\\n(71.6) °F\\n\\n28 °C\\n\\n(82.4) °F\\n\\n29.9 °C [...] | 21. October | 27 °C | 80 °F | 30 °C | 86 °F | 24 °C | 76 °F | 29 °C | 85 °F | 1.8 mm | 0.1 inch. |\\n| 22. October | 27 °C | 80 °F | 30 °C | 86 °F | 24 °C | 76 °F | 29 °C | 85 °F | 1.0 mm | 0.0 inch. |\\n| 23. October | 27 °C | 80 °F | 30 °C | 86 °F | 24 °C | 75 °F | 29 °C | 85 °F | 1.0 mm | 0.0 inch. |\\n| 24. October | 27 °C | 80 °F | 30 °C | 86 °F | 24 °C | 75 °F | 29 °C | 85 °F | 0.8 mm | 0.0 inch. |',\n",
       "  'score': 0.89501935},\n",
       " {'title': 'Weather in Chennai in October 2025 - Detailed Forecast',\n",
       "  'url': 'https://www.easeweather.com/asia/india/tamil-nadu/chennai/october',\n",
       "  'content': 'Until now, October 2025 in Chennai has been nearly identical to the historical average, with a temperature of 30.5 °C (showing only a slight deviation of -0.2 °C).\\n The forecast for the next days in Chennai predicts temperatures to be around 29 °C, close to the historical average.\\n In general, the average temperature in Chennai at the beginning of October is 32 °C. As the month progressed, temperatures tended to noticeably cool down, reaching an average of 29.3 °C by the end of October. [...] | 25 Oct. | Heavy rain | 27° /24° | 44.3 mm | 6 |\\n| 26 Oct. | Patchy rain possible | 29° /24° | 4.5 mm | 6 |\\n| 27 Oct. | Patchy rain possible | 30° /25° | 0.4 mm | 6 |\\n| 28 Oct. | Sunny | 31° /26° | 0 mm | 7 |\\n| 29 Oct. | Sunny | 30° /24° | 0 mm | 7 |\\n| 30 Oct. | Sunny | 29° /24° | 0 mm | 7 |\\n| 31 Oct. | Patchy rain possible | 29° /24° | 0.8 mm | 6 |\\n| Next | [...] | 16 Oct. | Light rain shower | 30° /25° | 20.4 mm | 6 |\\n| 17 Oct. | Sunny | 30° /26° | 3.3 mm | 7 |\\n| 18 Oct. | Partly cloudy | 30° /26° | 11 mm | 7 |\\n| 19 Oct. | Light rain shower | 29° /25° | 8.5 mm | 7 |\\n| 20 Oct. | Partly cloudy | 29° /26° | 13.6 mm | 7 |\\n| 21 Oct. | Partly cloudy | 30° /26° | 2.5 mm | 8 |\\n| 22 Oct. | Heavy rain | 29° /26° | 43.2 mm | 1.2 |\\n| 23 Oct. | Moderate rain | 28° /25° | 17.4 mm | 0.7 |\\n| 24 Oct. | Heavy rain | 25° /24° | 28.5 mm | 0.4 |',\n",
       "  'score': 0.8914433},\n",
       " {'title': 'New Low-Pressure Area Forms in Bay of Bengal,Chennai weather ...',\n",
       "  'url': 'https://www.livechennai.com/detailnews.asp?newsid=76385',\n",
       "  'content': '24/Oct/2025 5:20:11 PM\\n Gold Prices Take a U-Turn: Morning Surge Followed by Evening Drop \\n\\n  24/Oct/2025 4:49:05 PM\\n Cyclone Montha Likely to Form on Oct 27: Heavy Rain Alert for Chennai \\n\\n  24/Oct/2025 2:37:50 PM\\n The Glow of Subtle Confidence \\n\\n  24/Oct/2025 2:25:02 PM\\n Power Shutdown Areas in Chennai - Saturday (25-10-2025)\") \\n\\n  24/Oct/2025 2:16:54 PM\\n Chennai: Entry Fees Announced for Renovated Tholkappia Poonga \\n\\n  24/Oct/2025 1:47:14 PM\\n\\nWeb Development Company In Chennai',\n",
       "  'score': 0.87166095}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"What is the weather in chennai?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d606e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c271fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25efdec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4344586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0640a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d364c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f3c2b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in Chennai'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'High humidity with rain expected today; AQI improves | Chennai News', 'url': 'https://timesofindia.indiatimes.com/city/chennai/chennai-weather-update-patchy-rain-and-moderate-temperatures-expected-today/articleshow/124774193.cms', 'content': \"Chennai residents can expect scattered showers on October 24, 2025, with temperatures ranging between 23.4°C and 27°C and high humidity of 85%. The city's air quality index measured moderate at AQI-IN 62 yesterday, showing improvement from earlier in the week. The day will see winds at 22 km/h with an 89% chance of rain, particularly intensifying in the late afternoon.The morning will start with patchy rain and moderate humidity, creating muggy conditions. Light rain is expected to pick up by [...] Rao Narender Singh\\n\\nKasganj Parking Dispute\\n\\nDK Shivakumar\\n\\nMumbai Fire\\n\\nChennai Rains\\n\\n# Chennai weather: High humidity with rain expected today; AQI improves\\n\\nTIMESOFINDIA.COM / Updated: Oct 24, 2025, 17:47 IST\\n\\nShare\\n\\nAA\\n\\nText Size\\n\\n Small\\n Medium\\n Large [...] The weather outlook for the coming week shows varied conditions.October 25 will bring heavy rain with a high of 29.7°C, followed by patchy rain on October 26 with temperatures at 26.7°C.October 27 will experience moderate rain and strong winds at 32.4 km/h. October 28 will see a mix of sun and rain, with temperatures reaching 30.5°C.The week will conclude with sunny conditions on October 29 and 30, with temperatures rising to 31.9°C. The overall temperature range for the week will remain\", 'score': 0.97366726}, {'title': 'Chennai weather in October 2025 - Weather25.com', 'url': 'https://www.weather25.com/asia/india/tamil-nadu/chennai?page=month&month=October', 'content': 'United States England Australia Canada\\n\\n°F °C\\n\\nWeather in October 2025\\n\\n1. Home\\n2. Asia\\n3. India\\n4. Tamil Nadu\\n5. Chennai\\n6. October\\n\\nLocation was added to My Locations\\n\\nLocation was removed from My Locations\\n\\n# Chennai weather in October 2025\\n\\nClick on a day for an hourly weather forecast\\n\\nOct 24\\n\\n3.8 mm\\n\\n28° / 25°Oct 25\\n\\n4.3 mm\\n\\n31° / 24°Oct 26\\n\\n14.8 mm\\n\\n28° / 26°Monday\\n\\nOct 27\\n\\n43.3 mm\\n\\n24° / 24°Tuesday\\n\\nOct 28\\n\\n0 mm\\n\\n29° / 24°Wednesday\\n\\nOct 29\\n\\n0 mm\\n\\n32° / 25°Thursday\\n\\nOct 30\\n\\n0 mm [...] 32° / 27°\\n\\nRainy Days\\n\\n11\\n\\nSnowy Days\\n\\n0\\n\\nDry Days\\n\\n20\\n\\nRainfall\\n\\n292\\n\\nmm\\n\\nSun Hours\\n\\n11.3\\n\\nHrs\\n\\nHistoric average weather for October\\n\\nOctober [...] | 26  28° /26° | 27  24° /24° | 28  29° /24° | 29  32° /25° | 30  32° /27° | 31  31° /27° |', 'score': 0.94475573}, {'title': 'Weather Chennai in October 2025: Temperature & Climate', 'url': 'https://en.climate-data.org/asia/india/tamil-nadu/chennai-1003222/t/october-10/', 'content': '|  |  |  |  |  |  |\\n ---  ---  --- |\\n|  | Temperature October | 27.3°C | 81.1°F |  | Precipitation / Rainfall October | 223mm | 8.8 inches |\\n|  | Temperature October max. | 30.6°C | 87°F |  | Water Temperature October | 29°C | 85°F |\\n|  | Temperature October min. | 24.6°C | 76.3°F | [...] 24.3 °C\\n\\n(75.7) °F\\n\\n25.3 °C\\n\\n(77.5) °F\\n\\n27.4 °C\\n\\n(81.2) °F\\n\\n29.6 °C\\n\\n(85.3) °F\\n\\n31.3 °C\\n\\n(88.4) °F\\n\\n30.8 °C\\n\\n(87.5) °F\\n\\n30 °C\\n\\n(86) °F\\n\\n29.2 °C\\n\\n(84.6) °F\\n\\n28.7 °C\\n\\n(83.7) °F\\n\\n27.3 °C\\n\\n(81.1) °F\\n\\n25.7 °C\\n\\n(78.3) °F\\n\\n24.6 °C\\n\\n(76.3) °F\\n\\n20.8 °C\\n\\n(69.5) °F\\n\\n21 °C\\n\\n(69.9) °F\\n\\n23.1 °C\\n\\n(73.5) °F\\n\\n26.2 °C\\n\\n(79.1) °F\\n\\n28 °C\\n\\n(82.4) °F\\n\\n27.7 °C\\n\\n(81.9) °F\\n\\n27 °C\\n\\n(80.7) °F\\n\\n26.4 °C\\n\\n(79.5) °F\\n\\n26 °C\\n\\n(78.7) °F\\n\\n24.6 °C\\n\\n(76.3) °F\\n\\n23.3 °C\\n\\n(73.9) °F\\n\\n22 °C\\n\\n(71.6) °F\\n\\n28 °C\\n\\n(82.4) °F\\n\\n29.9 °C [...] | 21. October | 27 °C | 80 °F | 30 °C | 86 °F | 24 °C | 76 °F | 29 °C | 85 °F | 1.8 mm | 0.1 inch. |\\n| 22. October | 27 °C | 80 °F | 30 °C | 86 °F | 24 °C | 76 °F | 29 °C | 85 °F | 1.0 mm | 0.0 inch. |\\n| 23. October | 27 °C | 80 °F | 30 °C | 86 °F | 24 °C | 75 °F | 29 °C | 85 °F | 1.0 mm | 0.0 inch. |\\n| 24. October | 27 °C | 80 °F | 30 °C | 86 °F | 24 °C | 75 °F | 29 °C | 85 °F | 0.8 mm | 0.0 inch. |', 'score': 0.8923472}, {'title': 'Weather in Chennai in October 2025 - Detailed Forecast', 'url': 'https://www.easeweather.com/asia/india/tamil-nadu/chennai/october', 'content': '| 25 Oct. | Heavy rain | 27° /24° | 44.3 mm | 6 |\\n| 26 Oct. | Patchy rain possible | 29° /24° | 4.5 mm | 6 |\\n| 27 Oct. | Patchy rain possible | 30° /25° | 0.4 mm | 6 |\\n| 28 Oct. | Sunny | 31° /26° | 0 mm | 7 |\\n| 29 Oct. | Sunny | 30° /24° | 0 mm | 7 |\\n| 30 Oct. | Sunny | 29° /24° | 0 mm | 7 |\\n| 31 Oct. | Patchy rain possible | 29° /24° | 0.8 mm | 6 |\\n| Next | [...] Until now, October 2025 in Chennai has been nearly identical to the historical average, with a temperature of 30.5 °C (showing only a slight deviation of -0.2 °C).\\n The forecast for the next days in Chennai predicts temperatures to be around 29 °C, close to the historical average.\\n In general, the average temperature in Chennai at the beginning of October is 32 °C. As the month progressed, temperatures tended to noticeably cool down, reaching an average of 29.3 °C by the end of October. [...] | 16 Oct. | Light rain shower | 30° /25° | 20.4 mm | 6 |\\n| 17 Oct. | Sunny | 30° /26° | 3.3 mm | 7 |\\n| 18 Oct. | Partly cloudy | 30° /26° | 11 mm | 7 |\\n| 19 Oct. | Light rain shower | 29° /25° | 8.5 mm | 7 |\\n| 20 Oct. | Partly cloudy | 29° /26° | 13.6 mm | 7 |\\n| 21 Oct. | Partly cloudy | 30° /26° | 2.5 mm | 8 |\\n| 22 Oct. | Heavy rain | 29° /26° | 43.2 mm | 1.2 |\\n| 23 Oct. | Moderate rain | 28° /25° | 17.4 mm | 0.7 |\\n| 24 Oct. | Heavy rain | 25° /24° | 28.5 mm | 0.4 |', 'score': 0.8793233}, {'title': 'New Low-Pressure Area Forms in Bay of Bengal,Chennai weather ...', 'url': 'https://www.livechennai.com/detailnews.asp?newsid=76385', 'content': '24/Oct/2025 5:20:11 PM\\n Gold Prices Take a U-Turn: Morning Surge Followed by Evening Drop \\n\\n  24/Oct/2025 4:49:05 PM\\n Cyclone Montha Likely to Form on Oct 27: Heavy Rain Alert for Chennai \\n\\n  24/Oct/2025 2:37:50 PM\\n The Glow of Subtle Confidence \\n\\n  24/Oct/2025 2:25:02 PM\\n Power Shutdown Areas in Chennai - Saturday (25-10-2025)\") \\n\\n  24/Oct/2025 2:16:54 PM\\n Chennai: Entry Fees Announced for Renovated Tholkappia Poonga \\n\\n  24/Oct/2025 1:47:14 PM\\n\\nWeb Development Company In Chennai [...] Moderate rains accompanied by thunder and lightning are expected at several places in Tamil Nadu and Puducherry today and tomorrow. Rainfall is likely to continue until October 29. Heavy rainfall is forecast in select districts including Coimbatore, Nilgiris, Erode, Tirupattur, Vellore, and Ranipet today.\\n\\nPrevious   Next\\n\\n##### Top Stories\\n\\n Auspicious Time Tomorrow - October 25, 2025 (Saturday) : Plan Your Day with Nalla Neram : Plan Your Day with Nalla Neram\")', 'score': 0.8700796}]\u001b[0m\u001b[32;1m\u001b[1;3mBased on the weather forecast for Chennai on October 24, 2025, residents can expect scattered showers with temperatures ranging between 23.4°C and 27°C. The humidity will be high at 85%, with winds at 22 km/h. There is an 89% chance of rain, which is expected to intensify in the late afternoon. The city's air quality index is moderate at 62.\n",
      "\n",
      "The forecast for the coming week is as follows:\n",
      "* **October 25:** Heavy rain with a high of 29.7°C.\n",
      "* **October 26:** Patchy rain with temperatures at 26.7°C.\n",
      "* **October 27:** Moderate rain and strong winds at 32.4 km/h.\n",
      "* **October 28:** A mix of sun and rain with temperatures reaching 30.5°C.\n",
      "* **October 29 and 30:** Sunny conditions with temperatures rising to 31.9°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the weather in chennai?',\n",
       " 'output': \"Based on the weather forecast for Chennai on October 24, 2025, residents can expect scattered showers with temperatures ranging between 23.4°C and 27°C. The humidity will be high at 85%, with winds at 22 km/h. There is an 89% chance of rain, which is expected to intensify in the late afternoon. The city's air quality index is moderate at 62.\\n\\nThe forecast for the coming week is as follows:\\n* **October 25:** Heavy rain with a high of 29.7°C.\\n* **October 26:** Patchy rain with temperatures at 26.7°C.\\n* **October 27:** Moderate rain and strong winds at 32.4 km/h.\\n* **October 28:** A mix of sun and rain with temperatures reaching 30.5°C.\\n* **October 29 and 30:** Sunny conditions with temperatures rising to 31.9°C.\"}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"What is the weather in chennai?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10304741",
   "metadata": {},
   "source": [
    "## RAG creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "638b91c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f133f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3317d80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/', 'title': 'LangGraph Studio: The first agent IDE', 'description': 'LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.', 'language': 'en'}, page_content=\"\\n\\n\\nLangGraph Studio: The first agent IDE\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph Studio: The first agent IDE\\nLangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.\\n\\n4 min read\\nAug 1, 2024\\n\\n\\n\\n\\n\\nLLMs have paved the way for the development of new types of agentic applications — and as LLM applications evolve, so must the tooling needed to efficiently develop them. Today, we're announcing LangGraph Studio - the first IDE designed specifically for agent development - in open beta.LangGraph Studio offers a new way to develop LLM applications, providing a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. In this blog, we'll give a brief overview of LangGraph and then explore how LangGraph Studio streamlines the development of agentic applications.LangGraph: Balancing agent control with agency  In January 2023, we launched LangGraph, a highly controllable, low-level orchestration framework for building agentic applications. Since then, we've seen  teams build more complex agentic applications for production; in turn, we've heavily invested in LangGraph, leading to a stable 0.1 release this past June.LangGraph features a persistence layer that enables human-in-the-loop interactions, and it excels at building complex (i.e. more than a single LLM call) applications that require highly domain-specific cognitive architecture. Most of the agents we see in production fit this description.LangGraph is fully open source, available in both Python and Javascript. It works with or without LangChain, and integrates seamlessly with LangSmith.LangGraph Studio: Visualize and interact with agent graphs for quick iterationWhile LangGraph offers a new framework for developing agentic applications, we also strongly believe that new tooling is needed to make the development process easier. Building LLM applications differs from traditional software development, requiring different tooling outside of the traditional code editor.Coding is still important to developing LLM applications — after all, production-ready LangGraph applications have complicated custom logic in the nodes and edges of the graphs that are created. We don't aim to replace code editors but, instead, to augment the development experience with tools tailored for LangGraph applications. LangGraph Studio facilitates this by making it easy to visualize and interact with agent graphs, even if development still primarily happens in code. Visualizing graphs helps developers understand their structure. Furthermore, you can modify an agent result (or the logic underlying a specific node) halfway through the agent's trajectory. This creates an iterative process, by letting you interact with and manipulate the state at that point in time.While there is much more to explore, we're excited to introduce LangGraph Studio to start with bringing some of the core features of an agent IDE to the world.How to use LangGraph StudioLangGraph Studio is a desktop app, currently available for Apple Silicon. You can download a version here. Support for more platforms is coming soon.After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account. All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta. You can sign up for a LangSmith account here.After downloading LangSmith, you can open a directory. At a bare minimum, this directory needs to contain a Python file with a graph defined in it. Next, you will need to create a langgraph.json file containing details such as where the agent is defined, which dependencies to install, and which environment variables to load. This file can be created in the UI, or can exist as a file in the directory already. For an example repository which meets these requirements, see this GitHub repo.After you open a directory, we will build an environment for you agent to run. After it builds, you should see a visualization of the graph along with a box for interacting with the agent.When you interact with the agent, you'll get a stream of real-time information about what steps are happening. You can see the agent decide which tools to call, call those tools, and then continue looping. You can interrupt the agent at any time if veers off course, or you can interrupt the agent to run it in a “debug mode” where it pauses after each step of the graph (so you can walk-through step by step).\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0:00\\n\\n                            /0:19\\n\\n\\n1×\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n💡At any point, you can interact with the state of the agent.If you don’t like what the agent responded with at a specific step, you can directly modify the response and then continue with that new response. This can be useful for simulating what would have happened if the agent or a tool returned something different.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0:00\\n\\n                            /0:14\\n\\n\\n1×\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou can also modify the underlying code and then replay the node. LangGraph Studio detects changes to the underlying code files, allowing you to update prompts in your code editor and rerun nodes if an agent responds poorly. This can make it much easier to iterate on long-running agents.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0:00\\n\\n                            /0:20\\n\\n\\n1×\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nConclusionBuilding agentic applications differs from traditional software development. While code editors remain important, new IDEs designed for agents are also needed. LangGraph Studio is a step in this direction, and we're excited to see how it enhances your workflow.For more on LangGraph Studio, check out our documentation. You can also watch a video walkthrough on YouTube if that's more your style. You can\\xa0sign up for LangSmith\\xa0today to try out LangGraph Studio for free.We'd also love your feedback - drop us a line at hello@langchain.dev or on Twitter to share your thoughts.\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            © LangChain Blog 2025\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "689711e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0299f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "07705b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vector.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fce2137b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0:00\\n\\n                            /0:20\\n\\n\\n1×\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nConclusionBuilding agentic applications differs from traditional software development. While code editors remain important, new IDEs designed for agents are also needed. LangGraph Studio is a step in this direction, and we're excited to see how it enhances your workflow.For more on LangGraph Studio, check out our documentation. You can also watch a video walkthrough on YouTube if that's more your style. You can\\xa0sign up for LangSmith\\xa0today to try out LangGraph Studio for free.We'd also love your feedback - drop us a line at hello@langchain.dev or on Twitter to share your thoughts.\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            © LangChain Blog 2025\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what is langgraph studio?\")[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "686fd1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langgraph_studio\",\n",
    "    \"Search for information about LangGraph. For any further questions about LangGraph, you must use this tool.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4fe6dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "597c4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c6ecda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "32d66c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a497cf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langgraph_studio` with `{'query': 'what is langgraph studio'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m0:00\n",
      "\n",
      "                            /0:20\n",
      "\n",
      "\n",
      "1×\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ConclusionBuilding agentic applications differs from traditional software development. While code editors remain important, new IDEs designed for agents are also needed. LangGraph Studio is a step in this direction, and we're excited to see how it enhances your workflow.For more on LangGraph Studio, check out our documentation. You can also watch a video walkthrough on YouTube if that's more your style. You can sign up for LangSmith today to try out LangGraph Studio for free.We'd also love your feedback - drop us a line at hello@langchain.dev or on Twitter to share your thoughts.\n",
      "\n",
      "\n",
      "Join our newsletter\n",
      "Updates from the LangChain team and community\n",
      "\n",
      "\n",
      "Enter your email\n",
      "\n",
      "Subscribe\n",
      "\n",
      "Processing your application...\n",
      "Success! Please check your inbox and click the link to confirm your subscription.\n",
      "Sorry, something went wrong. Please try again.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sign up\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            © LangChain Blog 2025\n",
      "\n",
      "a specific node) halfway through the agent's trajectory. This creates an iterative process, by letting you interact with and manipulate the state at that point in time.While there is much more to explore, we're excited to introduce LangGraph Studio to start with bringing some of the core features of an agent IDE to the world.How to use LangGraph StudioLangGraph Studio is a desktop app, currently available for Apple Silicon. You can download a version here. Support for more platforms is coming soon.After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account. All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta. You can sign up for a LangSmith account here.After downloading LangSmith, you can open a directory. At a bare minimum, this directory needs to contain a Python file with a graph defined in it. Next, you will need to create a langgraph.json file containing details\n",
      "\n",
      "LangGraph Studio: The first agent IDE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Case Studies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In the Loop\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Changelog\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sign in\n",
      "Subscribe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangGraph Studio: The first agent IDE\n",
      "LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.\n",
      "\n",
      "4 min read\n",
      "Aug 1, 2024\u001b[0m\u001b[32;1m\u001b[1;3mLangGraph Studio is the first agent IDE, designed for visualizing, interacting with, and debugging complex agentic applications. It is a desktop app, currently available for Apple Silicon, with support for more platforms coming soon.\n",
      "\n",
      "To use LangGraph Studio, you will need to:\n",
      "\n",
      "1.  **Download LangGraph Studio.**\n",
      "2.  **Log in with your LangSmith account.** All LangSmith users, including those with free accounts, have access to LangGraph Studio while it is in beta.3.  **Open a directory.** This directory needs to contain a Python file with a graph defined in it and a `langgraph.json` file containing details.\n",
      "\n",
      "For more information, you can check out the LangGraph Studio documentation or watch a video walkthrough on YouTube.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi, what is langgraph studio? how to use it?',\n",
       " 'output': 'LangGraph Studio is the first agent IDE, designed for visualizing, interacting with, and debugging complex agentic applications. It is a desktop app, currently available for Apple Silicon, with support for more platforms coming soon.\\n\\nTo use LangGraph Studio, you will need to:\\n\\n1.  **Download LangGraph Studio.**\\n2.  **Log in with your LangSmith account.** All LangSmith users, including those with free accounts, have access to LangGraph Studio while it is in beta.3.  **Open a directory.** This directory needs to contain a Python file with a graph defined in it and a `langgraph.json` file containing details.\\n\\nFor more information, you can check out the LangGraph Studio documentation or watch a video walkthrough on YouTube.'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"hi, what is langgraph studio? how to use it?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef511ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'current weather in chennai'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Chennai Weather Today (Friday, Oct 24, 2025) - India Today', 'url': 'https://www.indiatoday.in/weather/chennai-weather-forecast-today', 'content': 'The minimum temperature in Chennai today is likely to hover around 24 degrees Celsius, while the maximum temperature might reach 31 degrees Celsius. The mercury level is expected to hover around 27 degrees Celsius throughout the day, with the wind speed around 4.38. The wind will move around 1 degrees with a gust speed of 5.83. The sunrise time is 06:00 AM, while it will set at 05:45 PM on Saturday. As per the seven-day weather prediction, the temperature in Chennai is likely to reach 31 [...] degrees Celsius on Saturday, 28 degrees Celsius on Sunday, 25 degrees Celsius on Monday, 29 degrees Celsius on Tuesday, 32 degrees Celsius on Wednesday, 33 degrees Celsius on Thursday and 32 degrees Celsius on Friday. [...] ### TRENDING TOPICS\\n\\n### Download App\\n\\n# Chennai Weather Today (Saturday, Oct 25, 2025)\\n\\nWeather Icon\\nmin\\nmax\\nrise\\nset\\nhumdity\\npressure\\nlon\\nlat\\nspeed\\ndeg\\ngust\\nRain\\nRain\\nRain\\nRain\\nClouds\\nClouds\\nClouds\\n\\n## Weather In Chennai', 'score': 0.9047265}, {'title': 'Weather in Chennai in October 2025 - Detailed Forecast', 'url': 'https://www.easeweather.com/asia/india/tamil-nadu/chennai/october', 'content': 'easeweather.com\\nIndia weather\\n\\n# Weather in Chennai for October 2025\\n\\n### Temperatures\\n\\nUntil now, October 2025 in Chennai has been nearly identical to the historical average, with a temperature of 30.1 °C (showing only a slight deviation of -0.3 °C).\\n\\nThe forecast for the next days in Chennai predicts temperatures to be around 30 °C, close to the historical average. [...] | 26 Oct. | Moderate rain Moderate rain | 28° /26° | 15.4 mm | 0.5 |  |\\n| 27 Oct. | Heavy rain Heavy rain | 24° /24° | 40.7 mm | 0.3 |  |\\n| 28 Oct. | Patchy rain possible Patchy rain possible | 29° /25° | 0.3 mm | 2.4 |  |\\n| 29 Oct. | Partly cloudy Partly cloudy | 32° /25° | 0 mm | 7 |  |\\n| 30 Oct. | Partly cloudy Partly cloudy | 32° /27° | 0 mm | 7 |  |\\n| 31 Oct. | Patchy rain possible Patchy rain possible | 31° /27° | 0.4 mm | 6 |  |\\n| Next | | | | | | [...] Patchy rain possible\\nPatchy rain possible\\nPartly cloudy\\nPatchy rain possible\\nPatchy light rain with thunder\\nPatchy rain possible\\nPatchy rain possible\\nPatchy rain possible\\nPatchy rain possible\\nPatchy rain possible\\nLight rain shower\\nSunny\\nPatchy rain possible\\nPartly cloudy\\nPatchy rain possible\\nLight rain shower\\nSunny\\nPartly cloudy\\nLight rain shower\\nPartly cloudy\\nPartly cloudy\\nPartly cloudy\\nSunny\\nSunny\\nModerate rain\\nModerate rain\\nHeavy rain\\nPatchy rain possible\\nPartly cloudy\\nPartly cloudy', 'score': 0.90123636}, {'title': 'Chennai - 14-Day Forecast: Temperature, Wind & Radar - Ventusky', 'url': 'https://www.ventusky.com/13.080;80.280', 'content': \"# Live Weather Forecast Maps\\n\\nRadar\\n\\n# Chennai\\n\\n13°5'N / 80°16'E / Altitude 9 m / 01:14 2025/10/25, Asia/Kolkata (UTC+5)\\n\\n|  |  |\\n --- |\\n| overcast | 26 °C |\\n|  |\\n| Wind speed  0 km/h |\\n\\novercast\\n\\n|  |  |\\n --- |\\n| Precipitation (24 hr.) | 1 mm |\\n| Air pressure | 1009 hPa |\\n| Visibility | 4 km |\\n| Clouds | 80 % |\\n| Cloud base | 600 m |\\n\\nWeather report from station Numgambakkam, Distance: 8 km (23:30 2025/10/24)\\n\\nOpen Radar Map\\n\\n## Weather for the next 24 hours\", 'score': 0.90039873}, {'title': 'Chennai, Tamil Nadu, India 14 day weather forecast - Time and Date', 'url': 'https://www.timeanddate.com/weather/india/chennai/ext', 'content': '| Sat Nov 8 |  | 92 / 77 °F | Scattered clouds. | 94 °F | 10 mph | ↑ | 48% | 3% | 0.00\" | 5 (Moderate) | 6:04 am | 5:40 pm |\\n|  |  |  |  |  |  |  |  |  |  |  |  |  |\\n ---  ---  ---  ---  ---  --- \\n| \\\\ Updated Friday, October 24, 2025 8:54:13 pm Chennai time - Weather by CustomWeather, © 2025 | | | | | | | | | | | | | [...] |  | Conditions | | | Comfort | | | | Precipitation | | Sun | | |\\n ---  ---  ---  ---  ---  --- \\n| Day |  | Temperature | Weather | Feels Like | Wind |  | Humidity | Chance | Amount | UV | Sunrise | Sunset |\\n| Sat Oct 25 |  | 89 / 75 °F | Isolated tstorms late. Overcast. | 99 °F | 8 mph | ↑ | 71% | 58% | 0.15\" | 5 (Moderate) | 6:00 am | 5:44 pm |\\n| Sun Oct 26 |  | 85 / 77 °F | Isolated tstorms. Overcast. | 92 °F | 7 mph | ↑ | 79% | 62% | 0.44\" | 3 (Moderate) | 6:01 am | 5:44 pm | [...] | Fri Oct 31 |  | 93 / 78 °F | Scattered clouds. | 103 °F | 10 mph | ↑ | 58% | 1% | 0.00\" | 7 (High) | 6:02 am | 5:42 pm |\\n| Sat Nov 1 |  | 91 / 75 °F | Mostly sunny. | 92 °F | 7 mph | ↑ | 45% | 4% | 0.00\" | 7 (High) | 6:02 am | 5:42 pm |\\n| Sun Nov 2 |  | 90 / 77 °F | Mostly cloudy. | 89 °F | 9 mph | ↑ | 41% | 5% | 0.00\" | 3 (Moderate) | 6:02 am | 5:41 pm |\\n| Mon Nov 3 |  | 92 / 77 °F | Broken clouds. | 96 °F | 4 mph | ↑ | 54% | 6% | 0.00\" | 7 (High) | 6:03 am | 5:41 pm |', 'score': 0.8865877}, {'title': 'Chennai weather in October 2025 - Weather25.com', 'url': 'https://www.weather25.com/asia/india/tamil-nadu/chennai?page=month&month=October', 'content': 'weather25.com\\nSearch\\nweather in India\\nRemove from your favorite locations\\nAdd to my locations\\nShare\\nweather in India\\n\\n# Chennai weather in October 2025\\n\\nPatchy rain possible\\nLight rain shower\\nHeavy rain\\nPatchy rain possible\\nPatchy rain possible\\nPatchy rain possible\\nPatchy rain possible\\nClear\\nClear\\nPartly cloudy\\nPartly cloudy\\nSunny\\nClear\\nClear\\n\\n## The average weather in Chennai in October [...] Patchy rain possible\\nPatchy rain possible\\nPartly cloudy\\nPatchy rain possible\\nPatchy rain possible\\nLight rain shower\\nLight rain shower\\nLight rain shower\\nLight rain shower\\nLight rain shower\\nLight rain shower\\nPatchy rain possible\\nLight rain shower\\nLight rain shower\\nPatchy rain possible\\nPatchy light drizzle\\nLight rain shower\\nPatchy rain possible\\nPartly cloudy\\nPatchy rain possible\\nLight rain shower\\nPatchy rain possible\\nPatchy rain possible\\nSunny\\nPatchy rain possible\\nLight rain shower\\nHeavy rain [...] The temperatures in Chennai during October are extremely high, between 27°C and hot as 32°C, drinking water regularly is advisable.\\n\\nYou can expect rain for roughly half of the month of October in Chennai. We’re expecting roughly 8 to 15 days of rain, so your rubber boots and umbrella are going to see plenty of use this month if you’re keen on staying dry.\\n\\nOur weather forecast can give you a great sense of what weather to expect in Chennai in October 2025.', 'score': 0.8684817}]\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in Chennai today, October 25, 2025, is overcast with a chance of isolated thunderstorms later in the day. The temperature is currently around 26-27°C. The maximum temperature for the day is expected to be around 31°C and the minimum temperature is expected to be around 24°C. There is a 58% chance of precipitation, and the humidity is around 71%. The wind speed is approximately 8 mph.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the current weather in chennai?',\n",
       " 'output': 'The weather in Chennai today, October 25, 2025, is overcast with a chance of isolated thunderstorms later in the day. The temperature is currently around 26-27°C. The maximum temperature for the day is expected to be around 31°C and the minimum temperature is expected to be around 24°C. There is a 58% chance of precipitation, and the humidity is around 71%. The wind speed is approximately 8 mph.'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"what is the current weather in chennai?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e333fe",
   "metadata": {},
   "source": [
    "## ReAct Agent (Reasoning + Acting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58f6c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f4daf803",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search = GoogleSerperAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Web Answer\",\n",
    "        func=google_search.run,\n",
    "        description=\"useful for when you need to ask with search\",\n",
    "        verbose=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4354348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''Answer the following questions as best as you can. You have access to the following tools:\n",
    "{tools}\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of the [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this thought/action/action input/observation can repeat N times)\n",
    "Thought: I know the final answer\n",
    "Final_answer: the final answer to the original input question\n",
    "Begin!\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6e8f0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d5a7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = create_react_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b04b034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=search_agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c857596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought:\n",
      "I need to identify the winner of the 2007 US PGA Championship, find their hometown, and find their winning score. I will first search for the winner and their score in that specific tournament, and then I will search for the winner's hometown.Action:\n",
      "Web Answer\n",
      "Action Input:\n",
      "who won 2007 US PGA championship and what was the score?\u001b[0mWeb Answer is not a valid tool, try one of [get_employee_salary, get_employee_id]."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `Thought: The user is asking a question about a historical sports event. The available tools are `get_employee_salary` and `get_employee_id`, which are for retrieving internal employee information. These tools are not suitable for answering a general knowledge question about a golf tournament. Therefore, I cannot answer the user's question. I need to inform the user that I cannot answer the question with the given tools.\nI know the final answer\nFinal_answer: I am sorry, but I cannot answer your question about the 2007 US PGA championship winner's hometown and score using the available tools, which are designed for retrieving employee information.`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/agent.py:1352\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1351\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/agent.py:455\u001b[39m, in \u001b[36mRunnableAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, **kwargs)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_runnable:\n\u001b[32m    449\u001b[39m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[32m    450\u001b[39m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3650\u001b[39m, in \u001b[36mRunnableSequence.stream\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3643\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3644\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\n\u001b[32m   3645\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3648\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   3649\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3650\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3636\u001b[39m, in \u001b[36mRunnableSequence.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3629\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3630\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   3631\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3634\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   3635\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3636\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_stream_with_config(\n\u001b[32m   3637\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3638\u001b[39m         \u001b[38;5;28mself\u001b[39m._transform,\n\u001b[32m   3639\u001b[39m         patch_config(config, run_name=(config \u001b[38;5;129;01mor\u001b[39;00m {}).get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name),\n\u001b[32m   3640\u001b[39m         **kwargs,\n\u001b[32m   3641\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:2372\u001b[39m, in \u001b[36mRunnable._transform_stream_with_config\u001b[39m\u001b[34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[39m\n\u001b[32m   2371\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2372\u001b[39m     chunk: Output = context.run(\u001b[38;5;28mnext\u001b[39m, iterator)\n\u001b[32m   2373\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3595\u001b[39m, in \u001b[36mRunnableSequence._transform\u001b[39m\u001b[34m(self, inputs, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   3593\u001b[39m         final_pipeline = step.transform(final_pipeline, config)\n\u001b[32m-> \u001b[39m\u001b[32m3595\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1589\u001b[39m, in \u001b[36mRunnable.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1588\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[32m-> \u001b[39m\u001b[32m1589\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream(final, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1155\u001b[39m, in \u001b[36mRunnable.stream\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1142\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Default implementation of ``stream``, which calls ``invoke``.\u001b[39;00m\n\u001b[32m   1143\u001b[39m \n\u001b[32m   1144\u001b[39m \u001b[33;03mSubclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1153\u001b[39m \n\u001b[32m   1154\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:200\u001b[39m, in \u001b[36mBaseOutputParser.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    210\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    211\u001b[39m     config,\n\u001b[32m    212\u001b[39m     run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    213\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:2092\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2089\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2090\u001b[39m         output = cast(\n\u001b[32m   2091\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2092\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2093\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2094\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2095\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2096\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2097\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2098\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2099\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2100\u001b[39m         )\n\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:201\u001b[39m, in \u001b[36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[39m\u001b[34m(inner_input)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    204\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    205\u001b[39m         config,\n\u001b[32m    206\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    207\u001b[39m     )\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    210\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    211\u001b[39m     config,\n\u001b[32m    212\u001b[39m     run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    213\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:254\u001b[39m, in \u001b[36mBaseOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m    242\u001b[39m \u001b[33;03mThe return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    252\u001b[39m \u001b[33;03m    Structured output.\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/output_parsers/react_single_input.py:76\u001b[39m, in \u001b[36mReActSingleInputOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     75\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[32m     77\u001b[39m         msg,\n\u001b[32m     78\u001b[39m         observation=MISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[32m     79\u001b[39m         llm_output=text,\n\u001b[32m     80\u001b[39m         send_to_llm=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     81\u001b[39m     )\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re.search(\n\u001b[32m     83\u001b[39m     \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]*Action\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*Input\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*:[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]*(.*)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     84\u001b[39m     text,\n\u001b[32m     85\u001b[39m     re.DOTALL,\n\u001b[32m     86\u001b[39m ):\n",
      "\u001b[31mOutputParserException\u001b[39m: Could not parse LLM output: `Thought: The user is asking a question about a historical sports event. The available tools are `get_employee_salary` and `get_employee_id`, which are for retrieving internal employee information. These tools are not suitable for answering a general knowledge question about a golf tournament. Therefore, I cannot answer the user's question. I need to inform the user that I cannot answer the question with the given tools.\nI know the final answer\nFinal_answer: I am sorry, but I cannot answer your question about the 2007 US PGA championship winner's hometown and score using the available tools, which are designed for retrieving employee information.`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[116]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhere is the hometown of the 2007 US PGA championship winner and his score?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/chains/base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   1326\u001b[39m             \u001b[38;5;28mself\u001b[39m._iter_next_step(\n\u001b[32m   1327\u001b[39m                 name_to_tool_map,\n\u001b[32m   1328\u001b[39m                 color_mapping,\n\u001b[32m   1329\u001b[39m                 inputs,\n\u001b[32m   1330\u001b[39m                 intermediate_steps,\n\u001b[32m   1331\u001b[39m                 run_manager,\n\u001b[32m   1332\u001b[39m             ),\n\u001b[32m   1333\u001b[39m         ),\n\u001b[32m   1334\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain/agents/agent.py:1369\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[32m   1363\u001b[39m     msg = (\n\u001b[32m   1364\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn output parsing error occurred. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1365\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1366\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1367\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1368\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1370\u001b[39m text = \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[31mValueError\u001b[39m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `Thought: The user is asking a question about a historical sports event. The available tools are `get_employee_salary` and `get_employee_id`, which are for retrieving internal employee information. These tools are not suitable for answering a general knowledge question about a golf tournament. Therefore, I cannot answer the user's question. I need to inform the user that I cannot answer the question with the given tools.\nI know the final answer\nFinal_answer: I am sorry, but I cannot answer your question about the 2007 US PGA championship winner's hometown and score using the available tools, which are designed for retrieving employee information.`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Where is the hometown of the 2007 US PGA championship winner and his score?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1f5b7",
   "metadata": {},
   "source": [
    "## ReAct with Custom Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5709f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "039572f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "@tool\n",
    "def get_employee_id(name):\n",
    "    \"\"\" To get employee id, it takes employee name as arguments\n",
    "    name(str): Name of the employee\n",
    "    \"\"\"\n",
    "    fake_employees = {\n",
    "        \"Alice\": \"E001\",\n",
    "        \"Bob\":\"E002\",\n",
    "        \"Charlie\": \"E003\",\n",
    "        \"Diana\": \"E004\",\n",
    "        \"Evan\": \"E005\",\n",
    "        \"Fiona\": \"E006\",\n",
    "        \"George\": \"E007\",\n",
    "        \"Hannah\": \"E008\",\n",
    "        \"Ian\": \"E009\",\n",
    "        \"Jessica\": \"E010\"\n",
    "    }\n",
    "    return fake_employees.get(name, \"Employee not Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aff48adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_employee_salary(employee_id):\n",
    "    \"\"\" To get the salary of an employee, it takes employee_id as input and returns salary\n",
    "    \"\"\"\n",
    "    employee_salaries = {\n",
    "    \"E001\": 56000,\n",
    "    \"E002\": 47000,\n",
    "    \"E003\": 52000,\n",
    "    \"E004\": 61000,\n",
    "    \"E005\": 45000,\n",
    "    \"E006\": 58000,\n",
    "    \"E007\": 49000,\n",
    "    \"E008\": 53000,\n",
    "    \"E009\": 50000,\n",
    "    \"E010\": 55000\n",
    "    }\n",
    "    return employee_salaries.get(employee_id, \"Employee not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f76af739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = hub.pull(\"hwchase17/react\")\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful HR assistant who can use tools to answer questions about employees.\",\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"\"\"User question: {input}\n",
    "\n",
    "Use tools if necessary to find the answer.\n",
    "{agent_scratchpad}\"\"\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7b1705ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_employee_salary, get_employee_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "91c8f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "abbee4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8313fa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_employee_id` with `{'name': 'Alice'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mE001\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_employee_salary` with `{'employee_id': 'E001'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m56000\u001b[0m\u001b[32;1m\u001b[1;3mThe salary of Alice is 56000.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the Salary of Alice?',\n",
       " 'output': 'The salary of Alice is 56000.'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is the Salary of Alice?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757672bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
