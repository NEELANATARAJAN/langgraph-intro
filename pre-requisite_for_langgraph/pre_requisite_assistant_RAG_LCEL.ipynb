{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc4dca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all okay\n"
     ]
    }
   ],
   "source": [
    "print(\"all okay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e05988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2acf511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGSMITH_API_KEY=os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT=os.getenv(\"LANGSMITH_PROJECT\")\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ac5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"]=GOOGLE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]=GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGSMITH_API_KEY\"]=LANGSMITH_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"]=LANGSMITH_PROJECT\n",
    "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"]=TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2f27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeladnatarajan/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761321648.319037  182054 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1761321648.395391  182054 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-pro\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7efe28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm2 = ChatGroq(model=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13411ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm doing great, thank you for asking! As an AI, I don't have feelings, but I'm fully operational and ready to help.\\n\\nHow can I assist you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--1c9a85e8-721c-49a9-9b97-cd071262209e-0', usage_metadata={'input_tokens': 6, 'output_tokens': 41, 'total_tokens': 944, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de24ba7",
   "metadata": {},
   "source": [
    "## Simple AI Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02faa222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is **New Delhi**.\n",
      "GoodBye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"Type your question. If you want to quit the chat write quit\")\n",
    "    if question.lower() != \"quit\":\n",
    "        print(llm.invoke(question).content)\n",
    "    else:\n",
    "        print(\"GoodBye!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da2cb479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langgraph-prerequisite'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGSMITH_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dc95911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759830980.034426  559721 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001 ['embedText', 'countTextTokens']\n",
      "models/gemini-2.5-pro-preview-03-25 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-05-20 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-06-17 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-05-06 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-06-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp-image-generation ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-preview-image-generation ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-exp-1206 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-tts ['countTokens', 'generateContent']\n",
      "models/gemini-2.5-pro-preview-tts ['countTokens', 'generateContent']\n",
      "models/learnlm-2.0-flash-experimental ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e4b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e2b-it ['generateContent', 'countTokens']\n",
      "models/gemini-flash-latest ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-flash-lite-latest ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-pro-latest ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-image-preview ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-image ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-preview-09-2025 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-09-2025 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-robotics-er-1.5-preview ['generateContent', 'countTokens']\n",
      "models/embedding-001 ['embedContent']\n",
      "models/text-embedding-004 ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-exp ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-001 ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
      "models/aqa ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 ['predict']\n",
      "models/imagen-4.0-generate-preview-06-06 ['predict']\n",
      "models/imagen-4.0-ultra-generate-preview-06-06 ['predict']\n",
      "models/imagen-4.0-generate-001 ['predict']\n",
      "models/imagen-4.0-ultra-generate-001 ['predict']\n",
      "models/imagen-4.0-fast-generate-001 ['predict']\n",
      "models/veo-2.0-generate-001 ['predictLongRunning']\n",
      "models/veo-3.0-generate-preview ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-preview ['predictLongRunning']\n",
      "models/veo-3.0-generate-001 ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-001 ['predictLongRunning']\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-live-001 ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-live-2.5-flash-preview ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-live-preview ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-native-audio-latest ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025 ['countTokens', 'bidiGenerateContent']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "models = genai.list_models()\n",
    "for m in models:\n",
    "    print(m.name, m.supported_generation_methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23597de2",
   "metadata": {},
   "source": [
    "## RAG based LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9f870cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ecacc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0994ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbcd0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"firstchat\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e133145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory = RunnableWithMessageHistory(llm, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb90b6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Neela Natarajan! It's a pleasure to meet you.\\n\\nHow can I help you today?\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"Hi! I'm neela natarajan\"), config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "716a599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm neela natarajan\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Neela Natarajan! It's a pleasure to meet you.\\n\\nHow can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--eaa73727-826a-49df-9d68-babcc1aeec63-0', usage_metadata={'input_tokens': 11, 'output_tokens': 24, 'total_tokens': 901, 'input_token_details': {'cache_read': 0}})])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c5362d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on your first message, your name is Neela Natarajan.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--5ab3881b-2703-45a4-a50a-337bef02cbfa-0', usage_metadata={'input_tokens': 44, 'output_tokens': 15, 'total_tokens': 798, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke(\"tell me what is my name?\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e689fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759865441.011745  559721 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "### Reading the text files from source directory\n",
    "\n",
    "loader = DirectoryLoader('../data', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "### BGE Embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "\n",
    "db = Chroma.from_documents(new_docs, embedding=embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbda1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fcbee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "| prompt\n",
    "| llm\n",
    "| StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3329e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, Llama 3 is a model.\n",
      "\n",
      "Here are 3 important points:\n",
      "1.  It was released in April 2024.\n",
      "2.  It has an 8B parameter version.\n",
      "3.  It is associated with Meta.\n"
     ]
    }
   ],
   "source": [
    "question = \"what is llama3? can you highlight 3 important points?\"\n",
    "print(retrieval_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b3c498",
   "metadata": {},
   "source": [
    "## Tools and Agents using LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63279fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "977cdf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adc759e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f08d43a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ecd2e79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "284c0938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'query to look up on wikipedia',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "070d02b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.return_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86f0eff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Vector database\n",
      "Summary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\n",
      "Vectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the\n"
     ]
    }
   ],
   "source": [
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "acc5c4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Vector database\\nSummary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\\nVectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd3eef",
   "metadata": {},
   "source": [
    "### Youtube search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b46995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d94e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2=YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26594e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube_search'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool2.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa883868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=HFFcMRtqH5A&pp=ygUVcmFtYXN3YW15IHN1YnJhbWFuaWFu', 'https://www.youtube.com/watch?v=RdWnAd5opXI&pp=ygUVcmFtYXN3YW15IHN1YnJhbWFuaWFu']\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool2.run(\"ramaswamy subramanian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f4a51",
   "metadata": {},
   "source": [
    "### Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57118ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3a0bcdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool3=TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b6ca47b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': \"Actor Vijay's TVK moves Supreme Court seeking independent probe ...\",\n",
       "  'url': 'https://www.thehindu.com/news/national/tamil-nadu/actor-vijays-tvk-moves-supreme-court-seeking-independent-probe-into-karur-stampede/article70138215.ece',\n",
       "  'content': \"Tamil actor Vijay's party TVK seeks Supreme Court probe into Karur stampede, challenging High Court's SIT formation.\",\n",
       "  'score': 0.98506},\n",
       " {'title': '2025 Karur crowd crush - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/2025_Karur_crowd_crush',\n",
       "  'content': 'On 27 September 2025, at least 41 people were killed and around 100 others were injured in a crowd crush during a political rally in Karur district,',\n",
       "  'score': 0.9838},\n",
       " {'title': 'Karur stampede: A visual timeline - Tamil Nadu - The Hindu',\n",
       "  'url': 'https://www.thehindu.com/news/national/tamil-nadu/karur-stampede-september-27-2025-tvk-vijay-visual-timeline/article70126058.ece',\n",
       "  'content': \"Karur stampede: This is how the tragedy during actor and Tamilaga Vettri Kazhagam (TVK) president Vijay's political rally unfolded on\",\n",
       "  'score': 0.98054},\n",
       " {'title': \"Karur stampede: TVK chief Vijay speaks to victims' families on video ...\",\n",
       "  'url': 'https://www.thehindu.com/news/national/tamil-nadu/karur-stampede-tvk-chief-vijay-speaks-to-victims-families-on-video-calls/article70134134.ece',\n",
       "  'content': 'Actor and TVK leader Vijay reaches out to families of stampede victims, offering condolences and support.',\n",
       "  'score': 0.97083},\n",
       " {'title': 'TVK approaches Supreme Court for independent probe into Karur ...',\n",
       "  'url': 'https://www.indiatoday.in/india/tamil-nadu/video/tvk-approaches-supreme-court-for-independent-probe-into-karur-stampede-2799601-2025-10-08',\n",
       "  'content': \"The legal battle over the Karur stampede has escalated to the Supreme Court. S.T.B.K's Aadhav Arjun has filed a plea seeking a Supreme\",\n",
       "  'score': 0.96801}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool3.invoke({\"query\": \"what happened in the latest karur stampede?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90aa2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbbcbe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65c071fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiInputs(BaseModel):\n",
    "    query: str = Field(description=\"query to look up in Wikipedia, should be 3 or less words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f643cc02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for WikipediaQueryRun\nargs_schema\n  Input should be a subclass of BaseModel [type=is_subclass_of, input_value=<class '__main__.WikiInputs'>, input_type=ModelMetaclass]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_subclass_of",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tool = \u001b[43mWikipediaQueryRun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwiki-tool\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlook up things in wikipedia\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWikiInputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_wrapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_direct\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/tools/base.py:525\u001b[39m, in \u001b[36mBaseTool.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    520\u001b[39m     msg = (\n\u001b[32m    521\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33margs_schema must be a subclass of pydantic BaseModel or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33ma JSON schema dict. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[33m'\u001b[39m\u001b[33margs_schema\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    523\u001b[39m     )\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/langchain_core/load/serializable.py:115\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DSProjects/LLMOps/hw/langgraph_studyset/langgraph-intro/venv/lib/python3.11/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for WikipediaQueryRun\nargs_schema\n  Input should be a subclass of BaseModel [type=is_subclass_of, input_value=<class '__main__.WikiInputs'>, input_type=ModelMetaclass]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_subclass_of"
     ]
    }
   ],
   "source": [
    "tool = WikipediaQueryRun(\n",
    "    name=\"wiki-tool\",\n",
    "    description=\"look up things in wikipedia\",\n",
    "    args_schema=WikiInputs,\n",
    "    api_wrapper=api_wrapper,\n",
    "    return_direct=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575afa18",
   "metadata": {},
   "source": [
    "## Predefined Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5a666c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Vector database\n",
      "Summary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\n",
      "Vectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector's position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.\n",
      "These feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other.\n",
      "Vector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.\n",
      "Vector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database. Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents. These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.\n",
      "\n",
      "\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information. With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM's pre-existing training data. This allows LLMs to use domain-specific and/or updated information that is not available in the training data. For example, this helps LLM-based chatbots access internal company data or generate responses based on authoritative sources.\n",
      "RAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have caused chatbots to describe policies that don't exist, or recommend nonexistent legal cases to lawyers that are looking for citations to support their arguments.\n",
      "RAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs. Beyond efficiency gains, RAG also allows LLMs to include sources in their responses, so users can verify the cited sources. This provides greater transparency, a\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "print(tool.run({\"query\": \"Langchain\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476fbcce",
   "metadata": {},
   "source": [
    "## Create a custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ecd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "@tool\n",
    "def get_word_length(word:str) -> int:\n",
    "    \"\"\" Returns the length of the given word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a2232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(get_word_length(\"MeenakshiRamaswamy\"))\n",
    "print(get_word_length(\"NeeladeviNatarajan\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "323b79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\" Returns the product of two integers.\"\"\" \n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "461c39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def summation(a: int, b: int) -> int:\n",
    "    \"\"\" Returns the sum of two integers.\"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1af6164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Returns the product of two integers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "305283a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"a\": 5, \"b\": 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9546540c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.invoke({\"a\": 9, \"b\": 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9671cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdbd3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf9c48ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/4n__nk894pn8cc6by3xc1xr00000gn/T/ipykernel_15810/2117554390.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent=initialize_agent(tool, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "agent=initialize_agent(tool, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cf957a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user is asking for a learning path for two related Python libraries: Langchain and Langgraph. I should provide a structured approach that starts with the fundamentals of Langchain and then moves on to the more advanced concepts in Langgraph. The best resources for learning software libraries are typically the official documentation, tutorials, and community-created content. I will structure my answer as a step-by-step guide.\n",
      "\n",
      "1.  **Start with the basics: What are they?** Briefly explain Langchain and Langgraph and their relationship. Langchain is the core framework for building LLM applications, and Langgraph is a library built on top of it for creating complex, stateful agentic systems as graphs.\n",
      "2.  **Lay out the learning path for Langchain:**\n",
      "    *   Point to the official documentation as the primary source.\n",
      "    *   Suggest starting with the \"Quickstart\" and core concepts like LCEL (LangChain Expression Language), Models, Prompts, and Chains.\n",
      "    *   Recommend building a simple application, like a RAG (Retrieval-Augmented Generation) app.\n",
      "    *   Mention key tutorials and video resources.\n",
      "3.  **Lay out the learning path for Langgraph:**\n",
      "    *   Emphasize that Langgraph should be learned *after* understanding Langchain.\n",
      "    *   Explain its core purpose: managing state and cycles (loops) in agentic workflows.\n",
      "    *   Direct the user to the Langgraph-specific documentation.\n",
      "    *   Highlight key concepts: StateGraph, Nodes, and Edges.\n",
      "    *   Suggest studying the official code examples, as they are very illustrative.\n",
      "4.  **Provide practical advice:**\n",
      "    *   Stress the importance of building projects.\n",
      "    *   Suggest joining community channels like Discord for help and updates.\n",
      "\n",
      "This plan doesn't require an external tool like Wikipedia, as the best information will come from the official project resources and my knowledge of how to learn a technical framework. I can formulate the final answer directly.\n",
      "I now know the final answer\n",
      "Final Answer: Learning Langchain and Langgraph is a great way to get into building sophisticated applications with Large Language Models (LLMs). Here is a structured, step-by-step guide to help you learn them effectively.\n",
      "\n",
      "### **Step 1: Understand the Core Concepts**\n",
      "\n",
      "First, understand what each library is for:\n",
      "*   **Langchain**: It's a comprehensive framework for developing applications powered by LLMs. It provides building blocks (components) and ways to chain them together to create everything from simple chatbots to complex agents.\n",
      "*   **Langgraph**: It's an extension of Langchain, specifically designed to build robust, stateful, multi-actor applications (agents) as graphs. It's ideal when you need loops, cycles, and more control over the flow of your agent's logic, which can be difficult with standard Langchain chains.\n",
      "\n",
      "**Key takeaway:** Learn Langchain first. Langgraph builds upon the concepts you'll learn in Langchain.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 2: Master the Fundamentals of Langchain**\n",
      "\n",
      "1.  **Start with the Official Documentation:** The Langchain Python documentation is the single best resource. Don't just read it; code along with the examples.\n",
      "    *   **Quickstart Guide:** Begin with the [Langchain Quickstart](https://python.langchain.com/docs/get_started/quickstart). This will walk you through setting up your environment and building your first simple LLM application.\n",
      "    *   **Learn LCEL (LangChain Expression Language):** This is the most crucial and modern way to compose chains in Langchain. It's a declarative syntax that makes building and customizing chains much easier. The entire \"LCEL\" section in the documentation is a must-read.\n",
      "    *   **Understand the Core Components:** Focus on these key modules:\n",
      "        *   **Models:** How to connect to different LLMs (like OpenAI, Anthropic, or open-source models).\n",
      "        *   **Prompts:** How to create dynamic, reusable prompts with prompt templates.\n",
      "        *   **Chains:** The core idea of linking components together using LCEL.\n",
      "        *   **Retrieval-Augmented Generation (RAG):** This is a very common and powerful pattern. Learn about Document Loaders, Text Splitters, Embeddings, and Vector Stores. The \"How-to\" section on RAG is excellent.\n",
      "\n",
      "2.  **Watch Video Tutorials:**\n",
      "    *   The official **Langchain YouTube Channel** has tutorials, deep dives, and project walkthroughs.\n",
      "    *   **FreeCodeCamp's \"LangChain & LLM Projects\"** course on YouTube is a comprehensive, project-based introduction.\n",
      "\n",
      "3.  **Build a Simple Project:** The best way to learn is by doing. A great first project is a simple RAG chatbot that can answer questions about a specific document (e.g., a PDF you provide).\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 3: Advance to Langgraph**\n",
      "\n",
      "Once you are comfortable with Langchain and have built a basic application, you're ready for Langgraph.\n",
      "\n",
      "1.  **Understand the \"Why\":** Standard Langchain chains are Directed Acyclic Graphs (DAGs), meaning they flow in one direction and don't have loops. Langgraph allows you to create graphs with **cycles**, which is essential for building agents that can reason, reflect, and retry actions until a goal is met.\n",
      "\n",
      "2.  **Go to the Langgraph Documentation:** Langgraph has its own dedicated section within the Langchain documentation.\n",
      "    *   **Start with the [Langgraph Overview](https://python.langchain.com/docs/langgraph):** This explains the core concepts and contrasts it with standard Langchain chains.\n",
      "    *   **Work Through the Tutorials:** The \"Getting Started\" tutorial is excellent. It shows you how to build a simple chatbot that can be easily extended.\n",
      "\n",
      "3.  **Focus on Key Langgraph Concepts:**\n",
      "    *   **`StatefulGraph` or `Graph`:** This is the main object you'll work with. It holds the state of your application.\n",
      "    *   **Nodes:** These are the \"steps\" in your graph. A node is typically a function or a Langchain runnable that performs an action (e.g., call an LLM, use a tool).\n",
      "    *   **Edges:** These are the connections between nodes that determine the flow of logic. You'll learn about the \"entry point,\" \"conditional edges\" (for routing logic), and the \"finish point.\"\n",
      "\n",
      "4.  **Study the Code Examples:** The [Langchain Cookbook repository on GitHub](https://github.com/langchain-ai/langchain/tree/master/cookbook) has a dedicated section for Langgraph with many practical, well-commented examples. These are invaluable for understanding how to apply Langgraph to real-world problems.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 4: Build Advanced Projects & Join the Community**\n",
      "\n",
      "1.  **Project Idea:** A great Langgraph project is to build a research assistant agent.\n",
      "    *   The agent takes a research topic.\n",
      "    *   **Node 1:** Uses a search tool to find relevant articles.\n",
      "    *   **Conditional Edge:** Checks if the articles are sufficient. If not, it loops back to search again with a modified query.\n",
      "    *   **Node 2:** If sufficient, it summarizes the articles.\n",
      "    *   **Node 3:** Writes a final report.\n",
      "\n",
      "2.  **Join the Community:**\n",
      "    *   **Langchain Discord:** A very active community where you can ask questions, share projects, and get help from developers and other users.\n",
      "    *   **GitHub:** Follow the Langchain and Langgraph repositories to see new features, report issues, and look at how others are using the libraries.\n",
      "    *   **X (formerly Twitter):** Follow the creators and key contributors for the latest updates and tips.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Learning Langchain and Langgraph is a great way to get into building sophisticated applications with Large Language Models (LLMs). Here is a structured, step-by-step guide to help you learn them effectively.\\n\\n### **Step 1: Understand the Core Concepts**\\n\\nFirst, understand what each library is for:\\n*   **Langchain**: It\\'s a comprehensive framework for developing applications powered by LLMs. It provides building blocks (components) and ways to chain them together to create everything from simple chatbots to complex agents.\\n*   **Langgraph**: It\\'s an extension of Langchain, specifically designed to build robust, stateful, multi-actor applications (agents) as graphs. It\\'s ideal when you need loops, cycles, and more control over the flow of your agent\\'s logic, which can be difficult with standard Langchain chains.\\n\\n**Key takeaway:** Learn Langchain first. Langgraph builds upon the concepts you\\'ll learn in Langchain.\\n\\n---\\n\\n### **Step 2: Master the Fundamentals of Langchain**\\n\\n1.  **Start with the Official Documentation:** The Langchain Python documentation is the single best resource. Don\\'t just read it; code along with the examples.\\n    *   **Quickstart Guide:** Begin with the [Langchain Quickstart](https://python.langchain.com/docs/get_started/quickstart). This will walk you through setting up your environment and building your first simple LLM application.\\n    *   **Learn LCEL (LangChain Expression Language):** This is the most crucial and modern way to compose chains in Langchain. It\\'s a declarative syntax that makes building and customizing chains much easier. The entire \"LCEL\" section in the documentation is a must-read.\\n    *   **Understand the Core Components:** Focus on these key modules:\\n        *   **Models:** How to connect to different LLMs (like OpenAI, Anthropic, or open-source models).\\n        *   **Prompts:** How to create dynamic, reusable prompts with prompt templates.\\n        *   **Chains:** The core idea of linking components together using LCEL.\\n        *   **Retrieval-Augmented Generation (RAG):** This is a very common and powerful pattern. Learn about Document Loaders, Text Splitters, Embeddings, and Vector Stores. The \"How-to\" section on RAG is excellent.\\n\\n2.  **Watch Video Tutorials:**\\n    *   The official **Langchain YouTube Channel** has tutorials, deep dives, and project walkthroughs.\\n    *   **FreeCodeCamp\\'s \"LangChain & LLM Projects\"** course on YouTube is a comprehensive, project-based introduction.\\n\\n3.  **Build a Simple Project:** The best way to learn is by doing. A great first project is a simple RAG chatbot that can answer questions about a specific document (e.g., a PDF you provide).\\n\\n---\\n\\n### **Step 3: Advance to Langgraph**\\n\\nOnce you are comfortable with Langchain and have built a basic application, you\\'re ready for Langgraph.\\n\\n1.  **Understand the \"Why\":** Standard Langchain chains are Directed Acyclic Graphs (DAGs), meaning they flow in one direction and don\\'t have loops. Langgraph allows you to create graphs with **cycles**, which is essential for building agents that can reason, reflect, and retry actions until a goal is met.\\n\\n2.  **Go to the Langgraph Documentation:** Langgraph has its own dedicated section within the Langchain documentation.\\n    *   **Start with the [Langgraph Overview](https://python.langchain.com/docs/langgraph):** This explains the core concepts and contrasts it with standard Langchain chains.\\n    *   **Work Through the Tutorials:** The \"Getting Started\" tutorial is excellent. It shows you how to build a simple chatbot that can be easily extended.\\n\\n3.  **Focus on Key Langgraph Concepts:**\\n    *   **`StatefulGraph` or `Graph`:** This is the main object you\\'ll work with. It holds the state of your application.\\n    *   **Nodes:** These are the \"steps\" in your graph. A node is typically a function or a Langchain runnable that performs an action (e.g., call an LLM, use a tool).\\n    *   **Edges:** These are the connections between nodes that determine the flow of logic. You\\'ll learn about the \"entry point,\" \"conditional edges\" (for routing logic), and the \"finish point.\"\\n\\n4.  **Study the Code Examples:** The [Langchain Cookbook repository on GitHub](https://github.com/langchain-ai/langchain/tree/master/cookbook) has a dedicated section for Langgraph with many practical, well-commented examples. These are invaluable for understanding how to apply Langgraph to real-world problems.\\n\\n---\\n\\n### **Step 4: Build Advanced Projects & Join the Community**\\n\\n1.  **Project Idea:** A great Langgraph project is to build a research assistant agent.\\n    *   The agent takes a research topic.\\n    *   **Node 1:** Uses a search tool to find relevant articles.\\n    *   **Conditional Edge:** Checks if the articles are sufficient. If not, it loops back to search again with a modified query.\\n    *   **Node 2:** If sufficient, it summarizes the articles.\\n    *   **Node 3:** Writes a final report.\\n\\n2.  **Join the Community:**\\n    *   **Langchain Discord:** A very active community where you can ask questions, share projects, and get help from developers and other users.\\n    *   **GitHub:** Follow the Langchain and Langgraph repositories to see new features, report issues, and look at how others are using the libraries.\\n    *   **X (formerly Twitter):** Follow the creators and key contributors for the latest updates and tips.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How to learn Langchain and Langgraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "976c7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "340c7766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/4n__nk894pn8cc6by3xc1xr00000gn/T/ipykernel_15810/1244456812.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  search = TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dde9ef15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Chennai weather in October 2025 - Weather25.com',\n",
       "  'url': 'https://www.weather25.com/asia/india/tamil-nadu/chennai?page=month&month=October',\n",
       "  'content': 'United States England Australia Canada\\n\\nF C\\n\\nWeather in October 2025\\n\\n1. Home\\n2. Asia\\n3. India\\n4. Tamil Nadu\\n5. Chennai\\n6. October\\n\\nLocation was added to My Locations\\n\\nLocation was removed from My Locations\\n\\n# Chennai weather in October 2025\\n\\nClick on a day for an hourly weather forecast\\n\\nOct 24\\n\\n3.8 mm\\n\\n28 / 25Oct 25\\n\\n4.3 mm\\n\\n31 / 24Oct 26\\n\\n14.8 mm\\n\\n28 / 26Monday\\n\\nOct 27\\n\\n43.3 mm\\n\\n24 / 24Tuesday\\n\\nOct 28\\n\\n0 mm\\n\\n29 / 24Wednesday\\n\\nOct 29\\n\\n0 mm\\n\\n32 / 25Thursday\\n\\nOct 30\\n\\n0 mm [...] 32 / 27\\n\\nRainy Days\\n\\n11\\n\\nSnowy Days\\n\\n0\\n\\nDry Days\\n\\n20\\n\\nRainfall\\n\\n292\\n\\nmm\\n\\nSun Hours\\n\\n11.3\\n\\nHrs\\n\\nHistoric average weather for October\\n\\nOctober [...] | 26  28 /26 | 27  24 /24 | 28  29 /24 | 29  32 /25 | 30  32 /27 | 31  31 /27 |',\n",
       "  'score': 0.94475573},\n",
       " {'title': 'New low-pressure area forms over Bay of Bengal, to bring heavy ...',\n",
       "  'url': 'https://www.thehindu.com/news/national/tamil-nadu/new-low-pressure-area-over-bay-of-bengal-to-bring-heavy-rain-to-tamil-nadu/article70196824.ece',\n",
       "  'content': 'Chennai city witnessed cloudy weather and drizzles on October 24, 2025\\n| Photo Credit: R. Ragu\\n\\nThe Regional Meteorological Centre (RMC), Chennai, has announced the formation of a new low-pressure area over the southeast Bay of Bengal, which is set to bring heavy rains to the northern districts of Tamil Nadu from Sunday (October 26, 2025). [...] ## According to the latest RMC bulletin, under the influence of an upper-air cyclonic circulation over the southeast Bay of Bengal and the adjoining south Andaman Sea, a low-pressure area has formed over the southeast Bay of Bengal as of 5.30 a.m. on Friday (October 24)\\n\\nUpdated  - October 24, 2025 06:21 pm IST - CHENNAI\\n\\nGoogle Preferred Source\\nChennai city witnessed cloudy weather and drizzles on October 24, 2025 [...] Pallipattu in Tiruvallur district received heaviest rainfall of 15 cm in the State over the past 24 hours ending 8.30 a.m. on Friday.\\n\\nPeople wade through stagnant rainwater at Koyambedu flower market in Chennai on October 24, 2025\\n\\nPeople wade through stagnant rainwater at Koyambedu flower market in Chennai on October 24, 2025\\n| Photo Credit:\\nB. Velankanni Raj',\n",
       "  'score': 0.93206495},\n",
       " {'title': 'Weather Chennai in October 2025: Temperature & Climate',\n",
       "  'url': 'https://en.climate-data.org/asia/india/tamil-nadu/chennai-1003222/t/october-10/',\n",
       "  'content': '|  |  |  |  |  |  |\\n ---  ---  --- |\\n|  | Temperature October | 27.3C | 81.1F |  | Precipitation / Rainfall October | 223mm | 8.8 inches |\\n|  | Temperature October max. | 30.6C | 87F |  | Water Temperature October | 29C | 85F |\\n|  | Temperature October min. | 24.6C | 76.3F | [...] 24.3 C\\n\\n(75.7) F\\n\\n25.3 C\\n\\n(77.5) F\\n\\n27.4 C\\n\\n(81.2) F\\n\\n29.6 C\\n\\n(85.3) F\\n\\n31.3 C\\n\\n(88.4) F\\n\\n30.8 C\\n\\n(87.5) F\\n\\n30 C\\n\\n(86) F\\n\\n29.2 C\\n\\n(84.6) F\\n\\n28.7 C\\n\\n(83.7) F\\n\\n27.3 C\\n\\n(81.1) F\\n\\n25.7 C\\n\\n(78.3) F\\n\\n24.6 C\\n\\n(76.3) F\\n\\n20.8 C\\n\\n(69.5) F\\n\\n21 C\\n\\n(69.9) F\\n\\n23.1 C\\n\\n(73.5) F\\n\\n26.2 C\\n\\n(79.1) F\\n\\n28 C\\n\\n(82.4) F\\n\\n27.7 C\\n\\n(81.9) F\\n\\n27 C\\n\\n(80.7) F\\n\\n26.4 C\\n\\n(79.5) F\\n\\n26 C\\n\\n(78.7) F\\n\\n24.6 C\\n\\n(76.3) F\\n\\n23.3 C\\n\\n(73.9) F\\n\\n22 C\\n\\n(71.6) F\\n\\n28 C\\n\\n(82.4) F\\n\\n29.9 C [...] | 21. October | 27 C | 80 F | 30 C | 86 F | 24 C | 76 F | 29 C | 85 F | 1.8 mm | 0.1 inch. |\\n| 22. October | 27 C | 80 F | 30 C | 86 F | 24 C | 76 F | 29 C | 85 F | 1.0 mm | 0.0 inch. |\\n| 23. October | 27 C | 80 F | 30 C | 86 F | 24 C | 75 F | 29 C | 85 F | 1.0 mm | 0.0 inch. |\\n| 24. October | 27 C | 80 F | 30 C | 86 F | 24 C | 75 F | 29 C | 85 F | 0.8 mm | 0.0 inch. |',\n",
       "  'score': 0.8923472},\n",
       " {'title': 'Weather in Chennai in October 2025 - Detailed Forecast',\n",
       "  'url': 'https://www.easeweather.com/asia/india/tamil-nadu/chennai/october',\n",
       "  'content': '| 25 Oct. | Heavy rain | 27 /24 | 44.3 mm | 6 |\\n| 26 Oct. | Patchy rain possible | 29 /24 | 4.5 mm | 6 |\\n| 27 Oct. | Patchy rain possible | 30 /25 | 0.4 mm | 6 |\\n| 28 Oct. | Sunny | 31 /26 | 0 mm | 7 |\\n| 29 Oct. | Sunny | 30 /24 | 0 mm | 7 |\\n| 30 Oct. | Sunny | 29 /24 | 0 mm | 7 |\\n| 31 Oct. | Patchy rain possible | 29 /24 | 0.8 mm | 6 |\\n| Next | [...] Until now, October 2025 in Chennai has been nearly identical to the historical average, with a temperature of 30.5 C (showing only a slight deviation of -0.2 C).\\n The forecast for the next days in Chennai predicts temperatures to be around 29 C, close to the historical average.\\n In general, the average temperature in Chennai at the beginning of October is 32 C. As the month progressed, temperatures tended to noticeably cool down, reaching an average of 29.3 C by the end of October. [...] | 16 Oct. | Light rain shower | 30 /25 | 20.4 mm | 6 |\\n| 17 Oct. | Sunny | 30 /26 | 3.3 mm | 7 |\\n| 18 Oct. | Partly cloudy | 30 /26 | 11 mm | 7 |\\n| 19 Oct. | Light rain shower | 29 /25 | 8.5 mm | 7 |\\n| 20 Oct. | Partly cloudy | 29 /26 | 13.6 mm | 7 |\\n| 21 Oct. | Partly cloudy | 30 /26 | 2.5 mm | 8 |\\n| 22 Oct. | Heavy rain | 29 /26 | 43.2 mm | 1.2 |\\n| 23 Oct. | Moderate rain | 28 /25 | 17.4 mm | 0.7 |\\n| 24 Oct. | Heavy rain | 25 /24 | 28.5 mm | 0.4 |',\n",
       "  'score': 0.8793233},\n",
       " {'title': 'Weather Forecast for Chennai for Friday 24 October',\n",
       "  'url': 'https://www.metcheck.com/WEATHER/dayforecast.asp?location=Chennai&locationID=2411041&lat=13.08784&lon=80.27847&dateFor=24/10/2025',\n",
       "  'content': ' Thu\\n 16 Days \\n Sat \\n\\n  \\n |  |  |\\n --- |\\n| Model/Location Information |  |\\n\\n|  |  |\\n --- |\\n| Models Used | MODELSUPDATED |\\n| Forecast Generated | 24 October 2025 07:56 BST |\\n| Latitude | 13.08784N |\\n| Longitude | 80.27847E |\\n| Moon | Moon Rise/Set Times  |\\n| Sun | Sun Rise/Set Times  |\\n\\n|  |  |\\n --- |\\n| Help & Information |  |\\n\\n|  |',\n",
       "  'score': 0.8646883}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"What is the weather in chennai?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d606e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c271fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25efdec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4344586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0640a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d364c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f3c2b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in chennai'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'High humidity with rain expected today; AQI improves | Chennai News', 'url': 'https://timesofindia.indiatimes.com/city/chennai/chennai-weather-update-patchy-rain-and-moderate-temperatures-expected-today/articleshow/124774193.cms', 'content': \"Chennai residents can expect scattered showers on October 24, 2025, with temperatures ranging between 23.4C and 27C and high humidity of 85%. The city's air quality index measured moderate at AQI-IN 62 yesterday, showing improvement from earlier in the week. The day will see winds at 22 km/h with an 89% chance of rain, particularly intensifying in the late afternoon.The morning will start with patchy rain and moderate humidity, creating muggy conditions. Light rain is expected to pick up by [...] Rao Narender Singh\\n\\nKasganj Parking Dispute\\n\\nDK Shivakumar\\n\\nMumbai Fire\\n\\nChennai Rains\\n\\n# Chennai weather: High humidity with rain expected today; AQI improves\\n\\nTIMESOFINDIA.COM / Updated: Oct 24, 2025, 17:47 IST\\n\\nShare\\n\\nAA\\n\\nText Size\\n\\n Small\\n Medium\\n Large [...] The weather outlook for the coming week shows varied conditions.October 25 will bring heavy rain with a high of 29.7C, followed by patchy rain on October 26 with temperatures at 26.7C.October 27 will experience moderate rain and strong winds at 32.4 km/h. October 28 will see a mix of sun and rain, with temperatures reaching 30.5C.The week will conclude with sunny conditions on October 29 and 30, with temperatures rising to 31.9C. The overall temperature range for the week will remain\", 'score': 0.9708237}, {'title': 'Chennai weather in October 2025 - Weather25.com', 'url': 'https://www.weather25.com/asia/india/tamil-nadu/chennai?page=month&month=October', 'content': 'United States England Australia Canada\\n\\nF C\\n\\nWeather in October 2025\\n\\n1. Home\\n2. Asia\\n3. India\\n4. Tamil Nadu\\n5. Chennai\\n6. October\\n\\nLocation was added to My Locations\\n\\nLocation was removed from My Locations\\n\\n# Chennai weather in October 2025\\n\\nClick on a day for an hourly weather forecast\\n\\nOct 24\\n\\n3.8 mm\\n\\n28 / 25Oct 25\\n\\n4.3 mm\\n\\n31 / 24Oct 26\\n\\n14.8 mm\\n\\n28 / 26Monday\\n\\nOct 27\\n\\n43.3 mm\\n\\n24 / 24Tuesday\\n\\nOct 28\\n\\n0 mm\\n\\n29 / 24Wednesday\\n\\nOct 29\\n\\n0 mm\\n\\n32 / 25Thursday\\n\\nOct 30\\n\\n0 mm [...] 32 / 27\\n\\nRainy Days\\n\\n11\\n\\nSnowy Days\\n\\n0\\n\\nDry Days\\n\\n20\\n\\nRainfall\\n\\n292\\n\\nmm\\n\\nSun Hours\\n\\n11.3\\n\\nHrs\\n\\nHistoric average weather for October\\n\\nOctober [...] | 26  28 /26 | 27  24 /24 | 28  29 /24 | 29  32 /25 | 30  32 /27 | 31  31 /27 |', 'score': 0.94225764}, {'title': 'Weather Chennai in October 2025: Temperature & Climate', 'url': 'https://en.climate-data.org/asia/india/tamil-nadu/chennai-1003222/t/october-10/', 'content': '|  |  |  |  |  |  |\\n ---  ---  --- |\\n|  | Temperature October | 27.3C | 81.1F |  | Precipitation / Rainfall October | 223mm | 8.8 inches |\\n|  | Temperature October max. | 30.6C | 87F |  | Water Temperature October | 29C | 85F |\\n|  | Temperature October min. | 24.6C | 76.3F | [...] 24.3 C\\n\\n(75.7) F\\n\\n25.3 C\\n\\n(77.5) F\\n\\n27.4 C\\n\\n(81.2) F\\n\\n29.6 C\\n\\n(85.3) F\\n\\n31.3 C\\n\\n(88.4) F\\n\\n30.8 C\\n\\n(87.5) F\\n\\n30 C\\n\\n(86) F\\n\\n29.2 C\\n\\n(84.6) F\\n\\n28.7 C\\n\\n(83.7) F\\n\\n27.3 C\\n\\n(81.1) F\\n\\n25.7 C\\n\\n(78.3) F\\n\\n24.6 C\\n\\n(76.3) F\\n\\n20.8 C\\n\\n(69.5) F\\n\\n21 C\\n\\n(69.9) F\\n\\n23.1 C\\n\\n(73.5) F\\n\\n26.2 C\\n\\n(79.1) F\\n\\n28 C\\n\\n(82.4) F\\n\\n27.7 C\\n\\n(81.9) F\\n\\n27 C\\n\\n(80.7) F\\n\\n26.4 C\\n\\n(79.5) F\\n\\n26 C\\n\\n(78.7) F\\n\\n24.6 C\\n\\n(76.3) F\\n\\n23.3 C\\n\\n(73.9) F\\n\\n22 C\\n\\n(71.6) F\\n\\n28 C\\n\\n(82.4) F\\n\\n29.9 C [...] | 21. October | 27 C | 80 F | 30 C | 86 F | 24 C | 76 F | 29 C | 85 F | 1.8 mm | 0.1 inch. |\\n| 22. October | 27 C | 80 F | 30 C | 86 F | 24 C | 76 F | 29 C | 85 F | 1.0 mm | 0.0 inch. |\\n| 23. October | 27 C | 80 F | 30 C | 86 F | 24 C | 75 F | 29 C | 85 F | 1.0 mm | 0.0 inch. |\\n| 24. October | 27 C | 80 F | 30 C | 86 F | 24 C | 75 F | 29 C | 85 F | 0.8 mm | 0.0 inch. |', 'score': 0.89501935}, {'title': 'Weather in Chennai in October 2025 - Detailed Forecast', 'url': 'https://www.easeweather.com/asia/india/tamil-nadu/chennai/october', 'content': 'Until now, October 2025 in Chennai has been nearly identical to the historical average, with a temperature of 30.5 C (showing only a slight deviation of -0.2 C).\\n The forecast for the next days in Chennai predicts temperatures to be around 29 C, close to the historical average.\\n In general, the average temperature in Chennai at the beginning of October is 32 C. As the month progressed, temperatures tended to noticeably cool down, reaching an average of 29.3 C by the end of October. [...] | 25 Oct. | Heavy rain | 27 /24 | 44.3 mm | 6 |\\n| 26 Oct. | Patchy rain possible | 29 /24 | 4.5 mm | 6 |\\n| 27 Oct. | Patchy rain possible | 30 /25 | 0.4 mm | 6 |\\n| 28 Oct. | Sunny | 31 /26 | 0 mm | 7 |\\n| 29 Oct. | Sunny | 30 /24 | 0 mm | 7 |\\n| 30 Oct. | Sunny | 29 /24 | 0 mm | 7 |\\n| 31 Oct. | Patchy rain possible | 29 /24 | 0.8 mm | 6 |\\n| Next | [...] | 16 Oct. | Light rain shower | 30 /25 | 20.4 mm | 6 |\\n| 17 Oct. | Sunny | 30 /26 | 3.3 mm | 7 |\\n| 18 Oct. | Partly cloudy | 30 /26 | 11 mm | 7 |\\n| 19 Oct. | Light rain shower | 29 /25 | 8.5 mm | 7 |\\n| 20 Oct. | Partly cloudy | 29 /26 | 13.6 mm | 7 |\\n| 21 Oct. | Partly cloudy | 30 /26 | 2.5 mm | 8 |\\n| 22 Oct. | Heavy rain | 29 /26 | 43.2 mm | 1.2 |\\n| 23 Oct. | Moderate rain | 28 /25 | 17.4 mm | 0.7 |\\n| 24 Oct. | Heavy rain | 25 /24 | 28.5 mm | 0.4 |', 'score': 0.8914433}, {'title': 'Weather Forecast for Chennai for Friday 24 October', 'url': 'https://www.metcheck.com/WEATHER/dayforecast.asp?location=Chennai&locationID=2411041&lat=13.08784&lon=80.27847&dateFor=24/10/2025', 'content': ' Thu\\n 16 Days \\n Sat \\n\\n  \\n |  |  |\\n --- |\\n| Model/Location Information |  |\\n\\n|  |  |\\n --- |\\n| Models Used | MODELSUPDATED |\\n| Forecast Generated | 24 October 2025 07:56 BST |\\n| Latitude | 13.08784N |\\n| Longitude | 80.27847E |\\n| Moon | Moon Rise/Set Times  |\\n| Sun | Sun Rise/Set Times  |\\n\\n|  |  |\\n --- |\\n| Help & Information |  |\\n\\n|  |', 'score': 0.86713725}]\u001b[0m\u001b[32;1m\u001b[1;3mI am sorry, I cannot give you the real-time weather. However, I can give you the forecast for October 24, 2025. There will be scattered showers with temperatures ranging between 23.4C and 27C and high humidity of 85%. The day will see winds at 22 km/h with an 89% chance of rain, particularly intensifying in the late afternoon.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the weather in chennai?',\n",
       " 'output': 'I am sorry, I cannot give you the real-time weather. However, I can give you the forecast for October 24, 2025. There will be scattered showers with temperatures ranging between 23.4C and 27C and high humidity of 85%. The day will see winds at 22 km/h with an 89% chance of rain, particularly intensifying in the late afternoon.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"What is the weather in chennai?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10304741",
   "metadata": {},
   "source": [
    "## RAG creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "638b91c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f133f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3317d80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/', 'title': 'LangGraph Studio: The first agent IDE', 'description': 'LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.', 'language': 'en'}, page_content=\"\\n\\n\\nLangGraph Studio: The first agent IDE\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph Studio: The first agent IDE\\nLangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.\\n\\n4 min read\\nAug 1, 2024\\n\\n\\n\\n\\n\\nLLMs have paved the way for the development of new types of agentic applications  and as LLM applications evolve, so must the tooling needed to efficiently develop them. Today, we're announcing LangGraph Studio - the first IDE designed specifically for agent development - in open beta.LangGraph Studio offers a new way to develop LLM applications, providing a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. In this blog, we'll give a brief overview of LangGraph and then explore how LangGraph Studio streamlines the development of agentic applications.LangGraph: Balancing agent control with agency  In January 2023, we launched LangGraph, a highly controllable, low-level orchestration framework for building agentic applications. Since then, we've seen  teams build more complex agentic applications for production; in turn, we've heavily invested in LangGraph, leading to a stable 0.1 release this past June.LangGraph features a persistence layer that enables human-in-the-loop interactions, and it excels at building complex (i.e. more than a single LLM call) applications that require highly domain-specific cognitive architecture. Most of the agents we see in production fit this description.LangGraph is fully open source, available in both Python and Javascript. It works with or without LangChain, and integrates seamlessly with LangSmith.LangGraph Studio: Visualize and interact with agent graphs for quick iterationWhile LangGraph offers a new framework for developing agentic applications, we also strongly believe that new tooling is needed to make the development process easier. Building LLM applications differs from traditional software development, requiring different tooling outside of the traditional code editor.Coding is still important to developing LLM applications  after all, production-ready LangGraph applications have complicated custom logic in the nodes and edges of the graphs that are created. We don't aim to replace code editors but, instead, to augment the development experience with tools tailored for LangGraph applications. LangGraph Studio facilitates this by making it easy to visualize and interact with agent graphs, even if development still primarily happens in code. Visualizing graphs helps developers understand their structure. Furthermore, you can modify an agent result (or the logic underlying a specific node) halfway through the agent's trajectory. This creates an iterative process, by letting you interact with and manipulate the state at that point in time.While there is much more to explore, we're excited to introduce LangGraph Studio to start with bringing some of the core features of an agent IDE to the world.How to use LangGraph StudioLangGraph Studio is a desktop app, currently available for Apple Silicon. You can download a version here. Support for more platforms is coming soon.After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account. All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta. You can sign up for a LangSmith account here.After downloading LangSmith, you can open a directory. At a bare minimum, this directory needs to contain a Python file with a graph defined in it. Next, you will need to create a langgraph.json file containing details such as where the agent is defined, which dependencies to install, and which environment variables to load. This file can be created in the UI, or can exist as a file in the directory already. For an example repository which meets these requirements, see this GitHub repo.After you open a directory, we will build an environment for you agent to run. After it builds, you should see a visualization of the graph along with a box for interacting with the agent.When you interact with the agent, you'll get a stream of real-time information about what steps are happening. You can see the agent decide which tools to call, call those tools, and then continue looping. You can interrupt the agent at any time if veers off course, or you can interrupt the agent to run it in a debug mode where it pauses after each step of the graph (so you can walk-through step by step).\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0:00\\n\\n                            /0:19\\n\\n\\n1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAt any point, you can interact with the state of the agent.If you dont like what the agent responded with at a specific step, you can directly modify the response and then continue with that new response. This can be useful for simulating what would have happened if the agent or a tool returned something different.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0:00\\n\\n                            /0:14\\n\\n\\n1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou can also modify the underlying code and then replay the node. LangGraph Studio detects changes to the underlying code files, allowing you to update prompts in your code editor and rerun nodes if an agent responds poorly. This can make it much easier to iterate on long-running agents.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0:00\\n\\n                            /0:20\\n\\n\\n1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nConclusionBuilding agentic applications differs from traditional software development. While code editors remain important, new IDEs designed for agents are also needed. LangGraph Studio is a step in this direction, and we're excited to see how it enhances your workflow.For more on LangGraph Studio, check out our documentation. You can also watch a video walkthrough on YouTube if that's more your style. You can\\xa0sign up for LangSmith\\xa0today to try out LangGraph Studio for free.We'd also love your feedback - drop us a line at hello@langchain.dev or on Twitter to share your thoughts.\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n             LangChain Blog 2025\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "689711e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0299f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07705b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vector.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fce2137b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0:00\\n\\n                            /0:20\\n\\n\\n1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nConclusionBuilding agentic applications differs from traditional software development. While code editors remain important, new IDEs designed for agents are also needed. LangGraph Studio is a step in this direction, and we're excited to see how it enhances your workflow.For more on LangGraph Studio, check out our documentation. You can also watch a video walkthrough on YouTube if that's more your style. You can\\xa0sign up for LangSmith\\xa0today to try out LangGraph Studio for free.We'd also love your feedback - drop us a line at hello@langchain.dev or on Twitter to share your thoughts.\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n             LangChain Blog 2025\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what is langgraph studio?\")[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "686fd1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langgraph_studio\",\n",
    "    \"Search for information about LangGraph. For any further questions about LangGraph, you must use this tool.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4fe6dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "597c4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c6ecda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "32d66c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a497cf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langgraph_studio` with `{'query': 'what is langgraph studio and how to use it'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m0:00\n",
      "\n",
      "                            /0:20\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ConclusionBuilding agentic applications differs from traditional software development. While code editors remain important, new IDEs designed for agents are also needed. LangGraph Studio is a step in this direction, and we're excited to see how it enhances your workflow.For more on LangGraph Studio, check out our documentation. You can also watch a video walkthrough on YouTube if that's more your style. You cansign up for LangSmithtoday to try out LangGraph Studio for free.We'd also love your feedback - drop us a line at hello@langchain.dev or on Twitter to share your thoughts.\n",
      "\n",
      "\n",
      "Join our newsletter\n",
      "Updates from the LangChain team and community\n",
      "\n",
      "\n",
      "Enter your email\n",
      "\n",
      "Subscribe\n",
      "\n",
      "Processing your application...\n",
      "Success! Please check your inbox and click the link to confirm your subscription.\n",
      "Sorry, something went wrong. Please try again.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sign up\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             LangChain Blog 2025\n",
      "\n",
      "a specific node) halfway through the agent's trajectory. This creates an iterative process, by letting you interact with and manipulate the state at that point in time.While there is much more to explore, we're excited to introduce LangGraph Studio to start with bringing some of the core features of an agent IDE to the world.How to use LangGraph StudioLangGraph Studio is a desktop app, currently available for Apple Silicon. You can download a version here. Support for more platforms is coming soon.After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account. All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta. You can sign up for a LangSmith account here.After downloading LangSmith, you can open a directory. At a bare minimum, this directory needs to contain a Python file with a graph defined in it. Next, you will need to create a langgraph.json file containing details\n",
      "\n",
      "is needed to make the development process easier. Building LLM applications differs from traditional software development, requiring different tooling outside of the traditional code editor.Coding is still important to developing LLM applications  after all, production-ready LangGraph applications have complicated custom logic in the nodes and edges of the graphs that are created. We don't aim to replace code editors but, instead, to augment the development experience with tools tailored for LangGraph applications. LangGraph Studio facilitates this by making it easy to visualize and interact with agent graphs, even if development still primarily happens in code. Visualizing graphs helps developers understand their structure. Furthermore, you can modify an agent result (or the logic underlying a specific node) halfway through the agent's trajectory. This creates an iterative process, by letting you interact with and manipulate the state at that point in time.While there is much more\u001b[0m\u001b[32;1m\u001b[1;3mOf course, I can help you with that.\n",
      "\n",
      "LangGraph Studio is a desktop Integrated Development Environment (IDE) designed for developing agentic applications. It's not meant to replace code editors, but rather to augment the development experience with tools tailored for LangGraph applications. It facilitates this by making it easy to visualize and interact with agent graphs, even if development still primarily happens in code.\n",
      "\n",
      "Here is how you can use LangGraph Studio:\n",
      "\n",
      "1.  **Download and Install**: LangGraph Studio is a desktop app, currently available for Apple Silicon. Support for more platforms is coming soon.\n",
      "2.  **Log in**: After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account. All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta.\n",
      "3.  **Open a Directory**: After downloading LangSmith, you can open a directory. At a bare minimum, this directory needs to contain a Python file with a graph defined in it.\n",
      "4.  **Create a Configuration File**: Next, you will need to create a `langgraph.json` file containing details about your project.\n",
      "\n",
      "For more information, you can check out the documentation or watch a video walkthrough on YouTube.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi, what is langgraph studio? how to use it?',\n",
       " 'output': \"Of course, I can help you with that.\\n\\nLangGraph Studio is a desktop Integrated Development Environment (IDE) designed for developing agentic applications. It's not meant to replace code editors, but rather to augment the development experience with tools tailored for LangGraph applications. It facilitates this by making it easy to visualize and interact with agent graphs, even if development still primarily happens in code.\\n\\nHere is how you can use LangGraph Studio:\\n\\n1.  **Download and Install**: LangGraph Studio is a desktop app, currently available for Apple Silicon. Support for more platforms is coming soon.\\n2.  **Log in**: After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account. All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta.\\n3.  **Open a Directory**: After downloading LangSmith, you can open a directory. At a bare minimum, this directory needs to contain a Python file with a graph defined in it.\\n4.  **Create a Configuration File**: Next, you will need to create a `langgraph.json` file containing details about your project.\\n\\nFor more information, you can check out the documentation or watch a video walkthrough on YouTube.\"}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"hi, what is langgraph studio? how to use it?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef511ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'current weather in chennai'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Chennai Weather Today (Friday, Oct 24, 2025) - India Today', 'url': 'https://www.indiatoday.in/weather/chennai-weather-forecast-today', 'content': 'The minimum temperature in Chennai today is likely to hover around 24 degrees Celsius, while the maximum temperature might reach 31 degrees Celsius. The mercury level is expected to hover around 27 degrees Celsius throughout the day, with the wind speed around 4.38. The wind will move around 1 degrees with a gust speed of 5.83. The sunrise time is 06:00 AM, while it will set at 05:45 PM on Saturday. As per the seven-day weather prediction, the temperature in Chennai is likely to reach 31 [...] degrees Celsius on Saturday, 28 degrees Celsius on Sunday, 25 degrees Celsius on Monday, 29 degrees Celsius on Tuesday, 32 degrees Celsius on Wednesday, 33 degrees Celsius on Thursday and 32 degrees Celsius on Friday. [...] ### TRENDING TOPICS\\n\\n### Download App\\n\\n# Chennai Weather Today (Saturday, Oct 25, 2025)\\n\\nWeather Icon\\nmin\\nmax\\nrise\\nset\\nhumdity\\npressure\\nlon\\nlat\\nspeed\\ndeg\\ngust\\nRain\\nRain\\nRain\\nRain\\nClouds\\nClouds\\nClouds\\n\\n## Weather In Chennai', 'score': 0.9047265}, {'title': 'Weather in Chennai in October 2025 - Detailed Forecast', 'url': 'https://www.easeweather.com/asia/india/tamil-nadu/chennai/october', 'content': 'easeweather.com\\nIndia weather\\n\\n# Weather in Chennai for October 2025\\n\\n### Temperatures\\n\\nUntil now, October 2025 in Chennai has been nearly identical to the historical average, with a temperature of 30.1 C (showing only a slight deviation of -0.3 C).\\n\\nThe forecast for the next days in Chennai predicts temperatures to be around 30 C, close to the historical average. [...] | 26 Oct. | Moderate rain Moderate rain | 28 /26 | 15.4 mm | 0.5 |  |\\n| 27 Oct. | Heavy rain Heavy rain | 24 /24 | 40.7 mm | 0.3 |  |\\n| 28 Oct. | Patchy rain possible Patchy rain possible | 29 /25 | 0.3 mm | 2.4 |  |\\n| 29 Oct. | Partly cloudy Partly cloudy | 32 /25 | 0 mm | 7 |  |\\n| 30 Oct. | Partly cloudy Partly cloudy | 32 /27 | 0 mm | 7 |  |\\n| 31 Oct. | Patchy rain possible Patchy rain possible | 31 /27 | 0.4 mm | 6 |  |\\n| Next | | | | | | [...] Patchy rain possible\\nPatchy rain possible\\nPartly cloudy\\nPatchy rain possible\\nPatchy light rain with thunder\\nPatchy rain possible\\nPatchy rain possible\\nPatchy rain possible\\nPatchy rain possible\\nPatchy rain possible\\nLight rain shower\\nSunny\\nPatchy rain possible\\nPartly cloudy\\nPatchy rain possible\\nLight rain shower\\nSunny\\nPartly cloudy\\nLight rain shower\\nPartly cloudy\\nPartly cloudy\\nPartly cloudy\\nSunny\\nSunny\\nModerate rain\\nModerate rain\\nHeavy rain\\nPatchy rain possible\\nPartly cloudy\\nPartly cloudy', 'score': 0.90123636}, {'title': 'Chennai - 14-Day Forecast: Temperature, Wind & Radar - Ventusky', 'url': 'https://www.ventusky.com/13.080;80.280', 'content': \"# Live Weather Forecast Maps\\n\\nRadar\\n\\n# Chennai\\n\\n135'N / 8016'E / Altitude 9 m / 00:56 2025/10/25, Asia/Kolkata (UTC+5)\\n\\n|  |  |\\n --- |\\n| overcast | 26 C |\\n|  |\\n| Wind speed  0 km/h |\\n\\novercast\\n\\n|  |  |\\n --- |\\n| Precipitation (24 hr.) | 1 mm |\\n| Air pressure | 1009 hPa |\\n| Visibility | 4 km |\\n| Clouds | 80 % |\\n| Cloud base | 600 m |\\n\\nWeather report from station Numgambakkam, Distance: 8 km (23:30 2025/10/24)\\n\\nOpen Radar Map\\n\\n## Weather for the next 24 hours [...] | 02:00 | 05:00 | 08:00 | 11:00 | 14:00 | 17:00 | 20:00 | 23:00 |\\n ---  ---  ---  --- |\\n| mixed with rain showers 26 C 0.4 mm 60 %  NW  9 km/h | mixed with rain showers 26 C 0.2 mm 60 %  NW  9 km/h | overcast 27 C 0.1 mm 70 %  NW  10 km/h | mixed with rain showers 28 C 0.4 mm 80 %  N  9 km/h | mixed with rain showers 28 C 1.7 mm 70 %  N  11 km/h | mostly cloudy 27 C 0 mm 50 %  N  11 km/h | overcast 27 C 0 mm 30 %  N  9 km/h | mixed with rain showers 26 C 1.9 mm 70 %  N  13 km/h | [...] | partly cloudy 26 C 0 mm 30 %  NW  6 km/h | partly cloudy 26 C 0 mm 20 %  W  5 km/h | mostly cloudy 26 C 0 mm 20 %  NW  6 km/h | mostly cloudy 26 C 0 mm 20 %  NW  8 km/h | mostly cloudy 26 C 0 mm 20 %  NW  8 km/h | partly cloudy 26 C 0 mm 10 %  NW  8 km/h | partly cloudy 26 C 0 mm 10 %  NW  9 km/h | mixed with rain showers 27 C 0.3 mm 50 %  N  9 km/h | mixed with rain showers 28 C 0.6 mm 60 %  N  9 km/h | rain, thunderstorms likely 29 C 0.8 mm 60 %  N  9 km/h | rain, thunderstorms\", 'score': 0.90018827}, {'title': 'Chennai weather in October 2025 - Weather25.com', 'url': 'https://www.weather25.com/asia/india/tamil-nadu/chennai?page=month&month=October', 'content': 'weather25.com\\nSearch\\nweather in India\\nRemove from your favorite locations\\nAdd to my locations\\nShare\\nweather in India\\n\\n# Chennai weather in October 2025\\n\\nPatchy rain possible\\nLight rain shower\\nHeavy rain\\nPatchy rain possible\\nPatchy rain possible\\nPatchy rain possible\\nPatchy rain possible\\nClear\\nClear\\nPartly cloudy\\nPartly cloudy\\nSunny\\nClear\\nClear\\n\\n## The average weather in Chennai in October [...] Patchy rain possible\\nPatchy rain possible\\nPartly cloudy\\nPatchy rain possible\\nPatchy rain possible\\nLight rain shower\\nLight rain shower\\nLight rain shower\\nLight rain shower\\nLight rain shower\\nLight rain shower\\nPatchy rain possible\\nLight rain shower\\nLight rain shower\\nPatchy rain possible\\nPatchy light drizzle\\nLight rain shower\\nPatchy rain possible\\nPartly cloudy\\nPatchy rain possible\\nLight rain shower\\nPatchy rain possible\\nPatchy rain possible\\nSunny\\nPatchy rain possible\\nLight rain shower\\nHeavy rain [...] The temperatures in Chennai during October are extremely high, between 27C and hot as 32C, drinking water regularly is advisable.\\n\\nYou can expect rain for roughly half of the month of October in Chennai. Were expecting roughly 8 to 15 days of rain, so your rubber boots and umbrella are going to see plenty of use this month if youre keen on staying dry.\\n\\nOur weather forecast can give you a great sense of what weather to expect in Chennai in October 2025.', 'score': 0.8684817}, {'title': 'Chennai weather in October 2025 | India: How hot?', 'url': 'https://www.weather2travel.com/india/chennai/october/', 'content': \"weather2travel.com - travel deals for your holiday in the sun\\nClick to search\\n\\n# Chennai weather in October 2025\\n\\nExpect  daytime maximum temperatures of 32C in Chennai, India in October and very high heat and humidity based on long-term weather averages. There are 6 hours of sunshine per day on average with typically 259 mm of rainfall in the month. [...] 32C maximum daytime temperature in October in Chennai\\n6 hours of sunshine per day (53% of daylight hours) in October in Chennai\\n9 days with some rainfall in October in Chennai\\n24C minimum night-time temperature in October in Chennai\\n12 hours of daylight per day in October in Chennai\\nVery high heat & humidity in October in Chennai\\n259 mm monthly rainfall in October in Chennai\\nUV (maximum) index 11 (Extreme) in October in Chennai\\n29C sea temperature in October in Chennai [...] There are normally 9 hours of bright sunshine each day in Chennai in October - that's 75% of daylight hours.\\n\\n### Does it ever rain in Chennai in October?\\n\\nThere is usually 1 day with some rain in Chennai in October and the average monthly rainfall is 24mm.\\n\\n## Chennai October sunrise & sunset times\\n\\nBrowse the sunrise and sunset times for Chennai in October 2025. Select a month to view Chennai sunrise and sunset times for the next 12 months.\\n\\nJanFebMarAprMayJunJulAugSepOctNovDec\", 'score': 0.84918517}]\u001b[0m\u001b[32;1m\u001b[1;3mI can't get you the exact real-time weather information, but I can give you a general overview of the current weather in Chennai. The weather in Chennai is currently overcast with a temperature of around 26C. The maximum temperature is expected to be 31C and the minimum is 24C. There is a possibility of rain, and the humidity is high.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the current weather in chennai?',\n",
       " 'output': \"I can't get you the exact real-time weather information, but I can give you a general overview of the current weather in Chennai. The weather in Chennai is currently overcast with a temperature of around 26C. The maximum temperature is expected to be 31C and the minimum is 24C. There is a possibility of rain, and the humidity is high.\"}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"what is the current weather in chennai?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6c2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
